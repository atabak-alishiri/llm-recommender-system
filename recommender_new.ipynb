{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eec1218-5ab8-4639-8adf-b5a969693d9d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "## Introduction\n",
    "This project aims to build a recommendation system using Amazon book review data, predicting how users would rate books they haven’t rated yet. The system enhances user experience by offering personalized book suggestions. Two key models are employed:\n",
    "\n",
    "**Collaborative Filtering**: The collaborative filtering model suggests books based on user-item interactions by identifying patterns in user behavior. It predicts a user’s rating of a book based on the ratings from similar users.\n",
    "The model achieved a Root Mean Squared Error (RMSE) of 0.94, indicating its performance in predicting ratings.\n",
    "Content-Based Filtering:\n",
    "\n",
    "After collaborative filtering, a **content-based model** is applied, incorporating vectors derived from user reviews as each product's features. These review vectors represent important aspects of each book based on the content of its reviews.\n",
    "By using these vectors, the model computes similarities between books and makes recommendations based on their content. This approach enhances the ability to recommend books with similar content to those the user has already rated.\n",
    "\n",
    "The content-based model showed a significant improvement in prediction accuracy, reducing the RMSE to 0.69—a notable improvement over the collaborative filtering model.\n",
    "This two-stage approach, first using collaborative filtering and then leveraging review-derived features in the content-based model, allows the system to generate more accurate and meaningful recommendations for users.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "6dbf6a5c-6590-4378-bdb9-b3c912dbf0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hashlib import sha1\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from surprise import SVD\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import accuracy\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b961be-5f3c-4426-ab30-15b14a53cacc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "## Data Description<a name=\"2\"></a>\n",
    "This project utilizes a comprehensive dataset sourced from Kaggle, which can be accessed via the following link: (https://www.kaggle.com/datasets/beaglelee/amazon-reviews-us-books-v1-02-tsv-zip). The dataset consists of 15 columns and encompasses a substantial total of 3,105,370 rows, providing rich insights into customer feedback and product ratings specifically within the book category.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "7bbe7833-717b-4df6-8ea4-8f3b2f147ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "data = pd.read_csv(\"data/amazon_reviews_us_Books_v1_02.tsv\", sep='\\t', on_bad_lines='skip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "bf3228b3-7f08-4f8e-a746-7abd2473b066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>12076615</td>\n",
       "      <td>RQ58W7SMO911M</td>\n",
       "      <td>0385730586</td>\n",
       "      <td>122662979</td>\n",
       "      <td>Sisterhood of the Traveling Pants (Book 1)</td>\n",
       "      <td>Books</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>this book was a great learning novel!</td>\n",
       "      <td>this boook was a great one that you could lear...</td>\n",
       "      <td>2005-10-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>12703090</td>\n",
       "      <td>RF6IUKMGL8SF</td>\n",
       "      <td>0811828964</td>\n",
       "      <td>56191234</td>\n",
       "      <td>The Bad Girl's Guide to Getting What You Want</td>\n",
       "      <td>Books</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Fun Fluff</td>\n",
       "      <td>If you are looking for something to stimulate ...</td>\n",
       "      <td>2005-10-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>12257412</td>\n",
       "      <td>R1DOSHH6AI622S</td>\n",
       "      <td>1844161560</td>\n",
       "      <td>253182049</td>\n",
       "      <td>Eisenhorn (A Warhammer 40,000 Omnibus)</td>\n",
       "      <td>Books</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>this isn't a review</td>\n",
       "      <td>never read it-a young relative idicated he lik...</td>\n",
       "      <td>2005-10-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>50732546</td>\n",
       "      <td>RATOTLA3OF70O</td>\n",
       "      <td>0373836635</td>\n",
       "      <td>348672532</td>\n",
       "      <td>Colby Conspiracy (Colby Agency)</td>\n",
       "      <td>Books</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>fine author on her A-game</td>\n",
       "      <td>Though she is honored to be Chicago Woman of t...</td>\n",
       "      <td>2005-10-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>51964897</td>\n",
       "      <td>R1TNWRKIVHVYOV</td>\n",
       "      <td>0262181533</td>\n",
       "      <td>598678717</td>\n",
       "      <td>The Psychology of Proof: Deductive Reasoning i...</td>\n",
       "      <td>Books</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Execellent cursor examination</td>\n",
       "      <td>Review based on a cursory examination by Unive...</td>\n",
       "      <td>2005-10-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "0          US     12076615   RQ58W7SMO911M  0385730586       122662979   \n",
       "1          US     12703090    RF6IUKMGL8SF  0811828964        56191234   \n",
       "2          US     12257412  R1DOSHH6AI622S  1844161560       253182049   \n",
       "3          US     50732546   RATOTLA3OF70O  0373836635       348672532   \n",
       "4          US     51964897  R1TNWRKIVHVYOV  0262181533       598678717   \n",
       "\n",
       "                                       product_title product_category  \\\n",
       "0         Sisterhood of the Traveling Pants (Book 1)            Books   \n",
       "1      The Bad Girl's Guide to Getting What You Want            Books   \n",
       "2             Eisenhorn (A Warhammer 40,000 Omnibus)            Books   \n",
       "3                    Colby Conspiracy (Colby Agency)            Books   \n",
       "4  The Psychology of Proof: Deductive Reasoning i...            Books   \n",
       "\n",
       "   star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "0          4.0            2.0          3.0    N                 N   \n",
       "1          3.0            5.0          5.0    N                 N   \n",
       "2          4.0            1.0         22.0    N                 N   \n",
       "3          5.0            2.0          2.0    N                 N   \n",
       "4          4.0            0.0          2.0    N                 N   \n",
       "\n",
       "                         review_headline  \\\n",
       "0  this book was a great learning novel!   \n",
       "1                              Fun Fluff   \n",
       "2                    this isn't a review   \n",
       "3              fine author on her A-game   \n",
       "4          Execellent cursor examination   \n",
       "\n",
       "                                         review_body review_date  \n",
       "0  this boook was a great one that you could lear...  2005-10-14  \n",
       "1  If you are looking for something to stimulate ...  2005-10-14  \n",
       "2  never read it-a young relative idicated he lik...  2005-10-14  \n",
       "3  Though she is honored to be Chicago Woman of t...  2005-10-14  \n",
       "4  Review based on a cursory examination by Unive...  2005-10-14  "
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5e2f95-f813-4cd3-879c-34b3d3f9cfc1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "## Exploratory Data Analysis(EDA) <a name=\"3\"></a>\n",
    "\n",
    "This section describes the exploratory data analysis (EDA) techniques employed to derive valuable insights from the dataset, which will inform the subsequent stages of model development.\n",
    "\n",
    "To create a targeted subset for analysis, we identified product IDs and customer IDs associated with at least 100 reviews. This filtering process resulted in a dataset containing 24,466 rows, representing customer reviews. Our final subset includes 1,672 distinct products and 1,230 distinct customers, ensuring a diverse representation of both products and customers. This comprehensive approach enables us to conduct a thorough examination of customer feedback, facilitating deeper insights into their preferences and behaviors.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "bf4c5e63-e457-4f53-ba53-3b7d23e0686e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3105370 entries, 0 to 3105369\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   marketplace        object \n",
      " 1   customer_id        int64  \n",
      " 2   review_id          object \n",
      " 3   product_id         object \n",
      " 4   product_parent     int64  \n",
      " 5   product_title      object \n",
      " 6   product_category   object \n",
      " 7   star_rating        float64\n",
      " 8   helpful_votes      float64\n",
      " 9   total_votes        float64\n",
      " 10  vine               object \n",
      " 11  verified_purchase  object \n",
      " 12  review_headline    object \n",
      " 13  review_body        object \n",
      " 14  review_date        object \n",
      "dtypes: float64(3), int64(2), object(10)\n",
      "memory usage: 355.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "bcb0bdf6-8c2d-409f-9640-e625aefc7f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marketplace            0\n",
       "customer_id            0\n",
       "review_id              0\n",
       "product_id             0\n",
       "product_parent         0\n",
       "product_title          0\n",
       "product_category       0\n",
       "star_rating            4\n",
       "helpful_votes          4\n",
       "total_votes            4\n",
       "vine                   4\n",
       "verified_purchase      4\n",
       "review_headline       57\n",
       "review_body            4\n",
       "review_date          133\n",
       "dtype: int64"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "ed0a5f88-14af-4fd4-baf2-b22a8cd3c122",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "bd566ae0-7c36-40be-b983-4456e5c79188",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace(['null', 'N/A', '', ' '], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "f8c3e030-ec22-4e02-9572-303fde59d229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marketplace          0\n",
       "customer_id          0\n",
       "review_id            0\n",
       "product_id           0\n",
       "product_parent       0\n",
       "product_title        0\n",
       "product_category     0\n",
       "star_rating          0\n",
       "helpful_votes        0\n",
       "total_votes          0\n",
       "vine                 0\n",
       "verified_purchase    0\n",
       "review_headline      0\n",
       "review_body          0\n",
       "review_date          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "56ec071b-1471-4a84-adbf-8353cfa1f418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marketplace                1\n",
       "customer_id          1502265\n",
       "review_id            3105184\n",
       "product_id            779692\n",
       "product_parent        666003\n",
       "product_title         713665\n",
       "product_category           1\n",
       "star_rating                5\n",
       "helpful_votes            942\n",
       "total_votes             1024\n",
       "vine                       2\n",
       "verified_purchase          2\n",
       "review_headline      2456998\n",
       "review_body          3070458\n",
       "review_date             3575\n",
       "dtype: int64"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "ee6755d9-ce24-4a8d-9a66-c8f580c147d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24459, 15)"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selected a subset with customers and products with at least 100 reviews\n",
    "# Step 1: Filter customers with at least 100 reviews\n",
    "customer_review_counts = data.groupby('customer_id').size().reset_index(name='review_count')\n",
    "customers_with_at_least_100_reviews = customer_review_counts[customer_review_counts['review_count'] >= 100]\n",
    "\n",
    "# Step 2: Filter products with at least 100 reviews\n",
    "product_review_counts = data.groupby('product_id').size().reset_index(name='review_count')\n",
    "products_with_at_least_100_reviews = product_review_counts[product_review_counts['review_count'] >= 100]\n",
    "\n",
    "# Step 3: Filter the original dataset to only include customers and products with at least 100 reviews\n",
    "filtered_data = data[\n",
    "    (data['customer_id'].isin(customers_with_at_least_100_reviews['customer_id'])) &\n",
    "    (data['product_id'].isin(products_with_at_least_100_reviews['product_id']))\n",
    "]\n",
    "filtered_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "134c1fee-9f44-4bac-a943-4e4573faea09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>US</td>\n",
       "      <td>50230169</td>\n",
       "      <td>R23MCAR8GSV3T0</td>\n",
       "      <td>0451526341</td>\n",
       "      <td>380925201</td>\n",
       "      <td>Animal farm: A Fairy Story</td>\n",
       "      <td>Books</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Simple Yet Profound</td>\n",
       "      <td>A generation ago, the sight of the cover of Ge...</td>\n",
       "      <td>2005-10-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>US</td>\n",
       "      <td>50776149</td>\n",
       "      <td>RUCZYTA3MP0MR</td>\n",
       "      <td>038551428X</td>\n",
       "      <td>970964974</td>\n",
       "      <td>The Traveler (Fourth Realm Trilogy, Book 1)</td>\n",
       "      <td>Books</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Great Marketing for a Pretty Good Book</td>\n",
       "      <td>The most interesting thing about this book is ...</td>\n",
       "      <td>2005-10-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>US</td>\n",
       "      <td>12598621</td>\n",
       "      <td>RCL2ARHKWH6RL</td>\n",
       "      <td>059035342X</td>\n",
       "      <td>667539744</td>\n",
       "      <td>Harry Potter and the Sorcerer's Stone</td>\n",
       "      <td>Books</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>I Think Part Of The Charm Is You Feel Like You...</td>\n",
       "      <td>Even though this is the shortest book in the H...</td>\n",
       "      <td>2005-10-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>US</td>\n",
       "      <td>49770667</td>\n",
       "      <td>R2P4B3STC980QP</td>\n",
       "      <td>1594480001</td>\n",
       "      <td>659516630</td>\n",
       "      <td>The Kite Runner</td>\n",
       "      <td>Books</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Praiseworthy first novel</td>\n",
       "      <td>Well I thoroughly enjoyed this book. Although ...</td>\n",
       "      <td>2005-10-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>US</td>\n",
       "      <td>49828549</td>\n",
       "      <td>RM0CSYVWKHW5W</td>\n",
       "      <td>0671027360</td>\n",
       "      <td>141370518</td>\n",
       "      <td>Angels &amp; Demons</td>\n",
       "      <td>Books</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Preposterous</td>\n",
       "      <td>Early in this novel, our hero finds out that a...</td>\n",
       "      <td>2005-10-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "295          US     50230169  R23MCAR8GSV3T0  0451526341       380925201   \n",
       "307          US     50776149   RUCZYTA3MP0MR  038551428X       970964974   \n",
       "314          US     12598621   RCL2ARHKWH6RL  059035342X       667539744   \n",
       "363          US     49770667  R2P4B3STC980QP  1594480001       659516630   \n",
       "406          US     49828549   RM0CSYVWKHW5W  0671027360       141370518   \n",
       "\n",
       "                                   product_title product_category  \\\n",
       "295                   Animal farm: A Fairy Story            Books   \n",
       "307  The Traveler (Fourth Realm Trilogy, Book 1)            Books   \n",
       "314        Harry Potter and the Sorcerer's Stone            Books   \n",
       "363                              The Kite Runner            Books   \n",
       "406                              Angels & Demons            Books   \n",
       "\n",
       "     star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "295          4.0            2.0          2.0    N                 N   \n",
       "307          5.0            2.0          5.0    N                 N   \n",
       "314          5.0            2.0          2.0    N                 N   \n",
       "363          5.0            4.0          4.0    N                 N   \n",
       "406          1.0           31.0         39.0    N                 N   \n",
       "\n",
       "                                       review_headline  \\\n",
       "295                                Simple Yet Profound   \n",
       "307             Great Marketing for a Pretty Good Book   \n",
       "314  I Think Part Of The Charm Is You Feel Like You...   \n",
       "363                           Praiseworthy first novel   \n",
       "406                                       Preposterous   \n",
       "\n",
       "                                           review_body review_date  \n",
       "295  A generation ago, the sight of the cover of Ge...  2005-10-14  \n",
       "307  The most interesting thing about this book is ...  2005-10-14  \n",
       "314  Even though this is the shortest book in the H...  2005-10-14  \n",
       "363  Well I thoroughly enjoyed this book. Although ...  2005-10-14  \n",
       "406  Early in this novel, our hero finds out that a...  2005-10-14  "
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "64c9e215-042b-45e3-be92-6d84b8400d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data.to_csv('data/amazon_reviews_subset_100.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "f3c23737-7b42-4942-8e8e-7b819d3d22a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marketplace              1\n",
       "customer_id           1229\n",
       "review_id            24459\n",
       "product_id            1672\n",
       "product_parent        1485\n",
       "product_title         1562\n",
       "product_category         1\n",
       "star_rating              5\n",
       "helpful_votes          423\n",
       "total_votes            460\n",
       "vine                     1\n",
       "verified_purchase        2\n",
       "review_headline      23298\n",
       "review_body          24307\n",
       "review_date           2574\n",
       "dtype: int64"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961a5e36-f4fd-45b6-8c43-6740dc262019",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "## Collaborative Filtering\n",
    "**Collaborative Filtering** is a widely-used technique for addressing the challenge of missing entries in a utility matrix, leveraging user behavior and interactions to make recommendations. This approach operates on the principle that users who have agreed in the past will continue to agree in the future, allowing the model to infer preferences based on the preferences of similar users.\n",
    "\n",
    "This method can be likened to advanced dimensionality reduction techniques such as Latent Semantic Analysis (LSA) or Truncated Singular Value Decomposition (SVD). By capturing the underlying relationships between users and items, collaborative filtering helps to predict missing values, enhancing the accuracy and relevance of recommendations.\n",
    "\n",
    "In this project, we implemented collaborative filtering as our baseline model to improve user experience by personalizing content based on historical data, thus enabling more informed decision-making.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "491d78cb-beef-48db-88bc-ddfb95474efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50230169</td>\n",
       "      <td>0451526341</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50776149</td>\n",
       "      <td>038551428X</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12598621</td>\n",
       "      <td>059035342X</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49770667</td>\n",
       "      <td>1594480001</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49828549</td>\n",
       "      <td>0671027360</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  product_id  star_rating\n",
       "0     50230169  0451526341          4.0\n",
       "1     50776149  038551428X          5.0\n",
       "2     12598621  059035342X          5.0\n",
       "3     49770667  1594480001          5.0\n",
       "4     49828549  0671027360          1.0"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the data\n",
    "coll_data = filtered_data[['customer_id', 'product_id', 'star_rating']].reset_index(drop=True)\n",
    "coll_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "ad78779c-6dbe-4255-a4f8-efe18c29515a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id    1229\n",
       "product_id     1672\n",
       "star_rating       5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll_data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "742f1968-46bc-490b-b7be-6a68094e4ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of customers (N)  : 1229\n",
      "Number of products (M) : 1672\n"
     ]
    }
   ],
   "source": [
    "# Number of customers and products\n",
    "user_key = \"customer_id\"\n",
    "item_key = \"product_id\"\n",
    "N = len(np.unique(coll_data[user_key])) \n",
    "M = len(np.unique(coll_data[item_key]))\n",
    "print(f\"Number of customers (N)  : {N}\")\n",
    "print(f\"Number of products (M) : {M}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "070d7eb1-ed77-4bba-b44b-f8fd9a0086dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-nan ratings percentage: 1.19\n"
     ]
    }
   ],
   "source": [
    "non_nan_ratings_percentage = (len(coll_data) / (N * M) * 100) \n",
    "print(f\"Non-nan ratings percentage: {np.round(non_nan_ratings_percentage,3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "3ca5bd28-648d-4812-923c-1b97f4b711fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of ratings per customer : 19.90\n",
      "Average number of ratings per product: 14.63\n"
     ]
    }
   ],
   "source": [
    "avg_nratings_per_user = coll_data.groupby(user_key).size().mean()\n",
    "avg_nratings_per_movie = coll_data.groupby(item_key).size().mean()\n",
    "print(f\"Average number of ratings per customer : {avg_nratings_per_user:.2f}\")\n",
    "print(f\"Average number of ratings per product: {avg_nratings_per_movie:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "01a72bc1-78c6-4ead-b28b-abb0a17873a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Splitting\n",
    "X = coll_data.copy()\n",
    "y = coll_data['customer_id']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "b70bb14a-b22d-4283-9d34-67b59d96b3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mapper = dict(zip(np.unique(coll_data[user_key]), list(range(N))))\n",
    "item_mapper = dict(zip(np.unique(coll_data[item_key]), list(range(M))))\n",
    "user_inverse_mapper = dict(zip(list(range(N)), np.unique(coll_data[user_key])))\n",
    "item_inverse_mapper = dict(zip(list(range(M)), np.unique(coll_data[item_key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "id": "c030f351-d414-410f-a4e2-be5ae058f3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Y_from_ratings(data, N, M):\n",
    "    Y = np.zeros((N, M))\n",
    "    Y.fill(np.nan)\n",
    "    for index, val in data.iterrows():\n",
    "        n = user_mapper[val[user_key]]\n",
    "        m = item_mapper[val[item_key]]\n",
    "        Y[n, m] = val[\"star_rating\"]\n",
    "\n",
    "    return Y\n",
    "\n",
    "train_mat = create_Y_from_ratings(X_train, N, M)\n",
    "valid_mat = create_Y_from_ratings(X_valid, N, M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "id": "0446201b-ba26-4bdb-8006-f9852b0d56e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-nan elements in train_mat: 19059\n",
      "Number of non-nan elements in valid_mat: 4858\n"
     ]
    }
   ],
   "source": [
    "# What's the number of non-nan elements in train_mat (nnn_train_mat)?\n",
    "nnn_train_mat = np.sum(~np.isnan(train_mat)) \n",
    "\n",
    "# What's the number of non-nan elements in valid_mat (nnn_valid_mat)?\n",
    "nnn_valid_mat = np.sum(~np.isnan(valid_mat)) \n",
    "print(f\"Number of non-nan elements in train_mat: {nnn_train_mat}\")\n",
    "print(f\"Number of non-nan elements in valid_mat: {nnn_valid_mat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "329bf88f-8133-49e8-823a-a03c2e5022c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "def error(Y1, Y2):\n",
    "    \"\"\"\n",
    "    Given two matrices of the same shape, \n",
    "    returns the root mean squared error (RMSE).\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.nanmean((Y1 - Y2) ** 2))\n",
    "\n",
    "\n",
    "def evaluate(pred_Y, train_mat, valid_mat, model_name=\"Global average\"):\n",
    "    \"\"\"\n",
    "    Given predicted utility matrix and train and validation utility matrices \n",
    "    print train and validation RMSEs.\n",
    "    \"\"\"\n",
    "    print(\"%s train RMSE: %0.2f\" % (model_name, error(pred_Y, train_mat)))\n",
    "    print(\"%s valid RMSE: %0.2f\" % (model_name, error(pred_Y, valid_mat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "0a2c14fa-0053-4ff2-b3a5-6fd4aa05b08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global average train RMSE: 1.06\n",
      "Global average valid RMSE: 1.09\n"
     ]
    }
   ],
   "source": [
    "# global average rating baseline\n",
    "avg = np.nanmean(train_mat)\n",
    "pred_g = np.zeros(train_mat.shape) + avg\n",
    "evaluate(pred_g, train_mat, valid_mat, model_name=\"Global average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "bfc44586-a17a-4aef-864d-a370f729bf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-user average train RMSE: 0.94\n",
      "Per-user average valid RMSE: 1.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j6/44dd1c8s33xg2kn35nxq3f5m0000gn/T/ipykernel_1490/2152599090.py:2: RuntimeWarning: Mean of empty slice\n",
      "  avg_n = np.nanmean(train_mat, axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Per-user average baseline\n",
    "avg_n = np.nanmean(train_mat, axis=1)\n",
    "avg_n[\n",
    "    np.isnan(avg_n)\n",
    "] = avg  \n",
    "pred_n = np.tile(avg_n[:, None], (1, M))\n",
    "evaluate(pred_n, train_mat, valid_mat, model_name=\"Per-user average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "681a3704-cc72-433d-a3d1-83c1844c1563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-product average train RMSE: 0.93\n",
      "Per-product average valid RMSE: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j6/44dd1c8s33xg2kn35nxq3f5m0000gn/T/ipykernel_1490/1388612677.py:2: RuntimeWarning: Mean of empty slice\n",
      "  avg_m = np.nanmean(train_mat, axis=0)\n"
     ]
    }
   ],
   "source": [
    "# Per-product average baseline\n",
    "avg_m = np.nanmean(train_mat, axis=0)\n",
    "avg_m[np.isnan(avg_m)] = avg\n",
    "pred_m = np.tile(avg_m[None, :], (N, 1))\n",
    "evaluate(pred_m, train_mat, valid_mat, model_name=\"Per-product average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "ff5925cb-82d4-40de-ac29-dfdc496ceafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-user and product average train RMSE: 0.88\n",
      "Per-user and product average valid RMSE: 0.99\n"
     ]
    }
   ],
   "source": [
    "# Average of per-user and per-product average baselines\n",
    "pred_n_m = (pred_n + pred_m) * 0.5\n",
    "evaluate(pred_n_m, train_mat, valid_mat, model_name=\"Per-user and product average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "705bb771-a661-4c89-9c40-909caf601848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of neighbours:  10\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 1.08\n",
      "\n",
      "Number of neighbours:  15\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 1.08\n",
      "\n",
      "Number of neighbours:  18\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 1.08\n",
      "\n",
      "Number of neighbours:  20\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 1.08\n",
      "\n",
      "Number of neighbours:  40\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 1.08\n"
     ]
    }
   ],
   "source": [
    "# K-nearest neighbours imputation\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "num_neighs = [10, 15, 18, 20, 40]\n",
    "for n_neighbors in num_neighs:\n",
    "    print(\"\\nNumber of neighbours: \", n_neighbors)\n",
    "    imputer = KNNImputer(n_neighbors=n_neighbors, keep_empty_features=True)\n",
    "    pred_knn = imputer.fit_transform(train_mat)\n",
    "    evaluate(pred_knn, train_mat, valid_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "id": "3294ab37-5558-4fed-ab30-8f9d1aac7ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TruncatedSVD (k = 10) train RMSE: 0.82\n",
      "TruncatedSVD (k = 10) valid RMSE: 0.98\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 50) train RMSE: 0.68\n",
      "TruncatedSVD (k = 50) valid RMSE: 0.98\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 100) train RMSE: 0.56\n",
      "TruncatedSVD (k = 100) valid RMSE: 0.97\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 200) train RMSE: 0.40\n",
      "TruncatedSVD (k = 200) valid RMSE: 0.97\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 500) train RMSE: 0.15\n",
      "TruncatedSVD (k = 500) valid RMSE: 0.97\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 1000) train RMSE: 0.01\n",
      "TruncatedSVD (k = 1000) valid RMSE: 0.97\n"
     ]
    }
   ],
   "source": [
    "# collaborative filtering with TruncatedSVD()\n",
    "def reconstruct_svd(Z, W, avg_n, avg_m):\n",
    "    return Z @ W + 0.5 * avg_n[:, None] + 0.5 * avg_m[None]\n",
    "\n",
    "\n",
    "train_mat_svd = train_mat - 0.5 * avg_n[:, None] - 0.5 * avg_m[None]\n",
    "train_mat_svd = np.nan_to_num(train_mat_svd)\n",
    "\n",
    "k_range = [10, 50, 100, 200, 500, 1000]\n",
    "for k in k_range:\n",
    "    print(\"\\n\")\n",
    "    tsvd = TruncatedSVD(n_components=k)\n",
    "    Z = tsvd.fit_transform(train_mat_svd)\n",
    "    W = tsvd.components_\n",
    "    X_hat = reconstruct_svd(Z, W, avg_n, avg_m)\n",
    "    evaluate(X_hat, train_mat, valid_mat, model_name=\"TruncatedSVD (k = %d)\" % k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "id": "e24b2cfc-a3ce-43ea-927c-750370cab260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using surprise package\n",
    "reader = Reader()\n",
    "data = Dataset.load_from_df(coll_data, reader)  \n",
    "\n",
    "k = 10\n",
    "algo = SVD(n_factors=k, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "id": "869fb9dd-5ae1-4a3b-b638-f34bb774cf7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9471  0.9443  0.9562  0.9424  0.9480  0.9476  0.0048  \n",
      "Fit time          0.02    0.02    0.02    0.02    0.02    0.02    0.00    \n",
      "Test time         0.01    0.01    0.01    0.01    0.01    0.01    0.00    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.947094</td>\n",
       "      <td>0.023036</td>\n",
       "      <td>0.008970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.944289</td>\n",
       "      <td>0.022839</td>\n",
       "      <td>0.008253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.956209</td>\n",
       "      <td>0.022565</td>\n",
       "      <td>0.008341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.942358</td>\n",
       "      <td>0.022773</td>\n",
       "      <td>0.008378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.948014</td>\n",
       "      <td>0.022638</td>\n",
       "      <td>0.008283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_rmse  fit_time  test_time\n",
       "0   0.947094  0.023036   0.008970\n",
       "1   0.944289  0.022839   0.008253\n",
       "2   0.956209  0.022565   0.008341\n",
       "3   0.942358  0.022773   0.008378\n",
       "4   0.948014  0.022638   0.008283"
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cross_validate(algo, data, measures=[\"RMSE\"], cv=5, verbose=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fdfa40-c5a4-4ee7-8b63-9cb1c031c7e4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "## Incorporating Reviews\n",
    "The model used makes predictions using features derived from product reviews, capturing the essence of each book’s content.\n",
    "\n",
    "The process involves several key steps:\n",
    "\n",
    "**Review Cleaning and Summarization**: The first step is to clean the raw reviews, removing irrelevant content, and ensuring the text data is ready for further analysis.\n",
    "The cleaned reviews are then summarized by product using the `facebook/bart-large-cnn` model. This summarization reduces the review data to its essential information for each product.\n",
    "\n",
    "**Vectorization**: Once the reviews are summarized, they are transformed into vectors using the `SentenceTransformer('all-MiniLM-L6-v2')` model. This converts the textual summaries into numerical representations (embeddings) that capture the semantic meaning of the reviews.\n",
    "\n",
    "**Dimensionality Reduction**: To handle the high dimensionality of the vectors, Principal Component Analysis (`PCA`) is applied. PCA reduces the complexity of the data while preserving the most important information, making the model more efficient without losing significant information.\n",
    "\n",
    "**Cosine Similarity**: With the reduced-dimension vectors, cosine similarity is used to measure the similarity between different products. This metric identifies products that are most similar to each other based on their review vectors.\n",
    "\n",
    "**Prediction and Evaluation**: The model predicts a user’s rating for an item by looking at the ratings of similar items they have already rated. A weighted average of these ratings is used to make predictions.\n",
    "The content-based model achieved an `RMSE` of 0.69 on the test set and an `RMSE` of 0.505 on the train set, indicating improved accuracy over the collaborative filtering model.\n",
    "\n",
    "This approach leverages both review content and sophisticated vectorization techniques to generate personalized and content-driven recommendations, significantly improving the model’s performance.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "1c5663cd-1d87-40b4-bcce-33393f8206e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50230169</td>\n",
       "      <td>0451526341</td>\n",
       "      <td>4.0</td>\n",
       "      <td>A generation ago, the sight of the cover of Ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50776149</td>\n",
       "      <td>038551428X</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The most interesting thing about this book is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12598621</td>\n",
       "      <td>059035342X</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Even though this is the shortest book in the H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49770667</td>\n",
       "      <td>1594480001</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Well I thoroughly enjoyed this book. Although ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49828549</td>\n",
       "      <td>0671027360</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Early in this novel, our hero finds out that a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  product_id  star_rating  \\\n",
       "0     50230169  0451526341          4.0   \n",
       "1     50776149  038551428X          5.0   \n",
       "2     12598621  059035342X          5.0   \n",
       "3     49770667  1594480001          5.0   \n",
       "4     49828549  0671027360          1.0   \n",
       "\n",
       "                                         review_body  \n",
       "0  A generation ago, the sight of the cover of Ge...  \n",
       "1  The most interesting thing about this book is ...  \n",
       "2  Even though this is the shortest book in the H...  \n",
       "3  Well I thoroughly enjoyed this book. Although ...  \n",
       "4  Early in this novel, our hero finds out that a...  "
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data = filtered_data[['customer_id', 'product_id', 'star_rating', 'review_body']].reset_index(drop=True)\n",
    "review_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "91118f4e-6303-4938-b649-46fc7e62fcf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24459, 4)"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "ddadfffb-02c4-438f-bc62-2f0500356f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "customer_id     1229\n",
       "product_id      1672\n",
       "star_rating        5\n",
       "review_body    24307\n",
       "dtype: int64"
      ]
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "a9d0ce39-eb3e-403a-bc96-1063b6b9cb5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>aggregated_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0020425651</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>susan cooper dark rising sequence joined pryda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0028610105</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>sheer diversity recipe japanese thai indian fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>006001203X</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>health care proffesional tell way traumatising...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0060096195</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>started reading one bathtub get id gotten fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>006016848X</td>\n",
       "      <td>3.562500</td>\n",
       "      <td>really like book time everyone want equality s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  average_rating  \\\n",
       "0  0020425651        5.000000   \n",
       "1  0028610105        4.400000   \n",
       "2  006001203X        4.100000   \n",
       "3  0060096195        4.428571   \n",
       "4  006016848X        3.562500   \n",
       "\n",
       "                                  aggregated_reviews  \n",
       "0  susan cooper dark rising sequence joined pryda...  \n",
       "1  sheer diversity recipe japanese thai indian fr...  \n",
       "2  health care proffesional tell way traumatising...  \n",
       "3  started reading one bathtub get id gotten fina...  \n",
       "4  really like book time everyone want equality s...  "
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean the reviews\n",
    "# Initialize stopwords and lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation and special characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Remove stopwords and lemmatize\n",
    "    text = ' '.join(lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words)\n",
    "    return text\n",
    "# Clean the 'review_body' column\n",
    "review_data['cleaned_review_body'] = review_data['review_body'].apply(clean_text)\n",
    "\n",
    "# Step 1: Group by 'customer_id' and 'product_id' and aggregate\n",
    "aggregated_data = review_data.groupby(['product_id']).agg(\n",
    "    average_rating=('star_rating', 'mean'),         # Mean of the star ratings\n",
    "    aggregated_reviews=('cleaned_review_body', ' '.join)  # Concatenate all cleaned review bodies\n",
    ").reset_index()\n",
    "\n",
    "# Display the aggregated DataFrame\n",
    "aggregated_data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "3f968123-0cdb-4d99-8c46-97d5cc6f3cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_id            1672\n",
       "average_rating         423\n",
       "aggregated_reviews    1672\n",
       "dtype: int64"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "ab2ae5b9-9913-44d1-84f1-3b67840ffbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1672, 3)"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "546a89ea-eb08-4054-ac6d-30e4898c5b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the BART model and tokenizer\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "58c0d1cd-207f-453d-83a5-7d5378727c2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/monorouzi/miniconda3/envs/563/lib/python3.11/site-packages/transformers/generation/utils.py:1158: UserWarning: Unfeasible length constraints: `min_length` (56) is larger than the maximum possible length (50). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def summarize_reviews(df):\n",
    "    summaries = []\n",
    "    for review in df['aggregated_reviews']:\n",
    "        inputs = tokenizer(review, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "        summary_ids = model.generate(inputs[\"input_ids\"], max_length=50, num_beams=4, early_stopping=True)\n",
    "        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        summaries.append(summary)\n",
    "    return summaries\n",
    "\n",
    "# Summarizing reviews \n",
    "aggregated_data['summarized_reviews'] = summarize_reviews(aggregated_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "78767ec1-849c-49ae-ab25-ed83e9a5bc7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>aggregated_reviews</th>\n",
       "      <th>summarized_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0020425651</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>susan cooper dark rising sequence joined pryda...</td>\n",
       "      <td>susan cooper dark rising sequence joined pryda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0028610105</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>sheer diversity recipe japanese thai indian fr...</td>\n",
       "      <td>sheer diversity recipe japanese thai indian fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>006001203X</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>health care proffesional tell way traumatising...</td>\n",
       "      <td>health care proffesional tell way traumatising...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0060096195</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>started reading one bathtub get id gotten fina...</td>\n",
       "      <td>started reading one bathtub get id gotten fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>006016848X</td>\n",
       "      <td>3.562500</td>\n",
       "      <td>really like book time everyone want equality s...</td>\n",
       "      <td>really like book time everyone want equality s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  average_rating  \\\n",
       "0  0020425651        5.000000   \n",
       "1  0028610105        4.400000   \n",
       "2  006001203X        4.100000   \n",
       "3  0060096195        4.428571   \n",
       "4  006016848X        3.562500   \n",
       "\n",
       "                                  aggregated_reviews  \\\n",
       "0  susan cooper dark rising sequence joined pryda...   \n",
       "1  sheer diversity recipe japanese thai indian fr...   \n",
       "2  health care proffesional tell way traumatising...   \n",
       "3  started reading one bathtub get id gotten fina...   \n",
       "4  really like book time everyone want equality s...   \n",
       "\n",
       "                                  summarized_reviews  \n",
       "0  susan cooper dark rising sequence joined pryda...  \n",
       "1  sheer diversity recipe japanese thai indian fr...  \n",
       "2  health care proffesional tell way traumatising...  \n",
       "3  started reading one bathtub get id gotten fina...  \n",
       "4  really like book time everyone want equality s...  "
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "d0a15928-db3d-40ca-9e50-1a5a84b855e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>summarized_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0020425651</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>susan cooper dark rising sequence joined pryda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0028610105</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>sheer diversity recipe japanese thai indian fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>006001203X</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>health care proffesional tell way traumatising...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0060096195</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>started reading one bathtub get id gotten fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>006016848X</td>\n",
       "      <td>3.562500</td>\n",
       "      <td>really like book time everyone want equality s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>1931412065</td>\n",
       "      <td>4.875000</td>\n",
       "      <td>confirmed low carber year year constant raveno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1668</th>\n",
       "      <td>1931498717</td>\n",
       "      <td>4.727273</td>\n",
       "      <td>selection book group sunday september since or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1669</th>\n",
       "      <td>1931561648</td>\n",
       "      <td>4.437500</td>\n",
       "      <td>said time traveler wife nonconventional love s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>1931866007</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>book consists transcript interview mike litman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>B0000WZWSI</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>first normally dont give many five star rating...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1672 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      product_id  average_rating  \\\n",
       "0     0020425651        5.000000   \n",
       "1     0028610105        4.400000   \n",
       "2     006001203X        4.100000   \n",
       "3     0060096195        4.428571   \n",
       "4     006016848X        3.562500   \n",
       "...          ...             ...   \n",
       "1667  1931412065        4.875000   \n",
       "1668  1931498717        4.727273   \n",
       "1669  1931561648        4.437500   \n",
       "1670  1931866007        5.000000   \n",
       "1671  B0000WZWSI        5.000000   \n",
       "\n",
       "                                     summarized_reviews  \n",
       "0     susan cooper dark rising sequence joined pryda...  \n",
       "1     sheer diversity recipe japanese thai indian fr...  \n",
       "2     health care proffesional tell way traumatising...  \n",
       "3     started reading one bathtub get id gotten fina...  \n",
       "4     really like book time everyone want equality s...  \n",
       "...                                                 ...  \n",
       "1667  confirmed low carber year year constant raveno...  \n",
       "1668  selection book group sunday september since or...  \n",
       "1669  said time traveler wife nonconventional love s...  \n",
       "1670  book consists transcript interview mike litman...  \n",
       "1671  first normally dont give many five star rating...  \n",
       "\n",
       "[1672 rows x 3 columns]"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_data[['product_id', 'average_rating', 'summarized_reviews']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "f5fb1915-1814-4f0e-8d0d-5358abaf719c",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_data.to_csv('data/summarized_review.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "582e645f-cc72-466a-8b84-88058830bed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data= aggregated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "28ecfc96-c663-4aa0-9493-cca3cbbf6609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>aggregated_reviews</th>\n",
       "      <th>summarized_reviews</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>374</th>\n",
       "      <th>375</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0020425651</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>susan cooper dark rising sequence joined pryda...</td>\n",
       "      <td>susan cooper dark rising sequence joined pryda...</td>\n",
       "      <td>-0.070799</td>\n",
       "      <td>-0.061837</td>\n",
       "      <td>-0.003631</td>\n",
       "      <td>0.012133</td>\n",
       "      <td>-0.035551</td>\n",
       "      <td>0.093195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065155</td>\n",
       "      <td>0.053727</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>0.088892</td>\n",
       "      <td>-0.042067</td>\n",
       "      <td>0.041044</td>\n",
       "      <td>0.070728</td>\n",
       "      <td>-0.043085</td>\n",
       "      <td>-0.064512</td>\n",
       "      <td>0.038242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0028610105</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>sheer diversity recipe japanese thai indian fr...</td>\n",
       "      <td>sheer diversity recipe japanese thai indian fr...</td>\n",
       "      <td>-0.073018</td>\n",
       "      <td>-0.023593</td>\n",
       "      <td>0.066772</td>\n",
       "      <td>0.036159</td>\n",
       "      <td>0.006666</td>\n",
       "      <td>-0.010815</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042942</td>\n",
       "      <td>0.037886</td>\n",
       "      <td>-0.001067</td>\n",
       "      <td>-0.009074</td>\n",
       "      <td>0.065551</td>\n",
       "      <td>-0.054624</td>\n",
       "      <td>0.067726</td>\n",
       "      <td>0.079832</td>\n",
       "      <td>-0.015437</td>\n",
       "      <td>-0.041357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>006001203X</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>health care proffesional tell way traumatising...</td>\n",
       "      <td>health care proffesional tell way traumatising...</td>\n",
       "      <td>0.004559</td>\n",
       "      <td>0.033951</td>\n",
       "      <td>0.020969</td>\n",
       "      <td>0.073957</td>\n",
       "      <td>-0.022270</td>\n",
       "      <td>0.056416</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005109</td>\n",
       "      <td>0.098458</td>\n",
       "      <td>0.004446</td>\n",
       "      <td>0.010148</td>\n",
       "      <td>-0.050168</td>\n",
       "      <td>0.036669</td>\n",
       "      <td>0.133147</td>\n",
       "      <td>0.013290</td>\n",
       "      <td>0.063390</td>\n",
       "      <td>0.043042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0060096195</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>started reading one bathtub get id gotten fina...</td>\n",
       "      <td>started reading one bathtub get id gotten fina...</td>\n",
       "      <td>-0.066638</td>\n",
       "      <td>-0.083743</td>\n",
       "      <td>0.053587</td>\n",
       "      <td>0.066727</td>\n",
       "      <td>-0.009095</td>\n",
       "      <td>0.022768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046725</td>\n",
       "      <td>0.029233</td>\n",
       "      <td>0.014859</td>\n",
       "      <td>0.084216</td>\n",
       "      <td>-0.085885</td>\n",
       "      <td>0.048461</td>\n",
       "      <td>0.023749</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>-0.075700</td>\n",
       "      <td>-0.034523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>006016848X</td>\n",
       "      <td>3.562500</td>\n",
       "      <td>really like book time everyone want equality s...</td>\n",
       "      <td>really like book time everyone want equality s...</td>\n",
       "      <td>-0.061388</td>\n",
       "      <td>0.048214</td>\n",
       "      <td>0.015069</td>\n",
       "      <td>-0.003492</td>\n",
       "      <td>-0.092024</td>\n",
       "      <td>0.022740</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041296</td>\n",
       "      <td>0.018716</td>\n",
       "      <td>0.018985</td>\n",
       "      <td>0.015178</td>\n",
       "      <td>-0.019459</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.134094</td>\n",
       "      <td>-0.078086</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>-0.001025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 388 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  average_rating  \\\n",
       "0  0020425651        5.000000   \n",
       "1  0028610105        4.400000   \n",
       "2  006001203X        4.100000   \n",
       "3  0060096195        4.428571   \n",
       "4  006016848X        3.562500   \n",
       "\n",
       "                                  aggregated_reviews  \\\n",
       "0  susan cooper dark rising sequence joined pryda...   \n",
       "1  sheer diversity recipe japanese thai indian fr...   \n",
       "2  health care proffesional tell way traumatising...   \n",
       "3  started reading one bathtub get id gotten fina...   \n",
       "4  really like book time everyone want equality s...   \n",
       "\n",
       "                                  summarized_reviews         0         1  \\\n",
       "0  susan cooper dark rising sequence joined pryda... -0.070799 -0.061837   \n",
       "1  sheer diversity recipe japanese thai indian fr... -0.073018 -0.023593   \n",
       "2  health care proffesional tell way traumatising...  0.004559  0.033951   \n",
       "3  started reading one bathtub get id gotten fina... -0.066638 -0.083743   \n",
       "4  really like book time everyone want equality s... -0.061388  0.048214   \n",
       "\n",
       "          2         3         4         5  ...       374       375       376  \\\n",
       "0 -0.003631  0.012133 -0.035551  0.093195  ...  0.065155  0.053727  0.003597   \n",
       "1  0.066772  0.036159  0.006666 -0.010815  ...  0.042942  0.037886 -0.001067   \n",
       "2  0.020969  0.073957 -0.022270  0.056416  ... -0.005109  0.098458  0.004446   \n",
       "3  0.053587  0.066727 -0.009095  0.022768  ...  0.046725  0.029233  0.014859   \n",
       "4  0.015069 -0.003492 -0.092024  0.022740  ...  0.041296  0.018716  0.018985   \n",
       "\n",
       "        377       378       379       380       381       382       383  \n",
       "0  0.088892 -0.042067  0.041044  0.070728 -0.043085 -0.064512  0.038242  \n",
       "1 -0.009074  0.065551 -0.054624  0.067726  0.079832 -0.015437 -0.041357  \n",
       "2  0.010148 -0.050168  0.036669  0.133147  0.013290  0.063390  0.043042  \n",
       "3  0.084216 -0.085885  0.048461  0.023749  0.003057 -0.075700 -0.034523  \n",
       "4  0.015178 -0.019459  0.000856  0.134094 -0.078086  0.004868 -0.001025  \n",
       "\n",
       "[5 rows x 388 columns]"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a pre-trained model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2') \n",
    "\n",
    "# Encode the summaries to get embeddings\n",
    "embeddings = model.encode(sample_data['summarized_reviews'].tolist())\n",
    "\n",
    "# Convert embeddings to a DataFrame\n",
    "embeddings_df = pd.DataFrame(embeddings)\n",
    "\n",
    "vectorized_data = pd.concat([sample_data, embeddings_df], axis=1)\n",
    "vectorized_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "0dcf4837-b69c-4cef-a11a-042480032f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>aggregated_reviews</th>\n",
       "      <th>summarized_reviews</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0020425651</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>susan cooper dark rising sequence joined pryda...</td>\n",
       "      <td>susan cooper dark rising sequence joined pryda...</td>\n",
       "      <td>0.635252</td>\n",
       "      <td>-0.269045</td>\n",
       "      <td>0.012184</td>\n",
       "      <td>-0.010487</td>\n",
       "      <td>0.058941</td>\n",
       "      <td>0.251971</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.184776</td>\n",
       "      <td>-0.035200</td>\n",
       "      <td>-0.052860</td>\n",
       "      <td>0.074156</td>\n",
       "      <td>-0.033203</td>\n",
       "      <td>0.029792</td>\n",
       "      <td>0.076104</td>\n",
       "      <td>0.132746</td>\n",
       "      <td>0.045042</td>\n",
       "      <td>0.031042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0028610105</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>sheer diversity recipe japanese thai indian fr...</td>\n",
       "      <td>sheer diversity recipe japanese thai indian fr...</td>\n",
       "      <td>0.261072</td>\n",
       "      <td>0.044054</td>\n",
       "      <td>0.130190</td>\n",
       "      <td>0.080427</td>\n",
       "      <td>-0.001261</td>\n",
       "      <td>0.046605</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.078350</td>\n",
       "      <td>-0.052345</td>\n",
       "      <td>0.057356</td>\n",
       "      <td>0.110849</td>\n",
       "      <td>0.248279</td>\n",
       "      <td>-0.254497</td>\n",
       "      <td>0.029056</td>\n",
       "      <td>0.108632</td>\n",
       "      <td>0.106938</td>\n",
       "      <td>0.194251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>006001203X</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>health care proffesional tell way traumatising...</td>\n",
       "      <td>health care proffesional tell way traumatising...</td>\n",
       "      <td>0.257239</td>\n",
       "      <td>0.295282</td>\n",
       "      <td>0.238382</td>\n",
       "      <td>0.178325</td>\n",
       "      <td>-0.077830</td>\n",
       "      <td>0.070369</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021567</td>\n",
       "      <td>0.065485</td>\n",
       "      <td>0.269843</td>\n",
       "      <td>0.109493</td>\n",
       "      <td>0.062807</td>\n",
       "      <td>-0.056614</td>\n",
       "      <td>0.152163</td>\n",
       "      <td>-0.151631</td>\n",
       "      <td>-0.050819</td>\n",
       "      <td>0.159799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0060096195</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>started reading one bathtub get id gotten fina...</td>\n",
       "      <td>started reading one bathtub get id gotten fina...</td>\n",
       "      <td>0.683657</td>\n",
       "      <td>-0.247198</td>\n",
       "      <td>0.033077</td>\n",
       "      <td>0.060875</td>\n",
       "      <td>-0.078793</td>\n",
       "      <td>-0.056407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039104</td>\n",
       "      <td>-0.121871</td>\n",
       "      <td>0.087071</td>\n",
       "      <td>0.013348</td>\n",
       "      <td>0.125837</td>\n",
       "      <td>0.046312</td>\n",
       "      <td>-0.081648</td>\n",
       "      <td>0.077465</td>\n",
       "      <td>-0.085890</td>\n",
       "      <td>-0.125254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>006016848X</td>\n",
       "      <td>3.562500</td>\n",
       "      <td>really like book time everyone want equality s...</td>\n",
       "      <td>really like book time everyone want equality s...</td>\n",
       "      <td>0.492497</td>\n",
       "      <td>0.233496</td>\n",
       "      <td>0.105420</td>\n",
       "      <td>0.168974</td>\n",
       "      <td>0.087518</td>\n",
       "      <td>-0.126515</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033602</td>\n",
       "      <td>-0.117381</td>\n",
       "      <td>-0.153551</td>\n",
       "      <td>-0.093654</td>\n",
       "      <td>0.013880</td>\n",
       "      <td>0.031424</td>\n",
       "      <td>0.073882</td>\n",
       "      <td>-0.089763</td>\n",
       "      <td>-0.055060</td>\n",
       "      <td>-0.027179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  average_rating  \\\n",
       "0  0020425651        5.000000   \n",
       "1  0028610105        4.400000   \n",
       "2  006001203X        4.100000   \n",
       "3  0060096195        4.428571   \n",
       "4  006016848X        3.562500   \n",
       "\n",
       "                                  aggregated_reviews  \\\n",
       "0  susan cooper dark rising sequence joined pryda...   \n",
       "1  sheer diversity recipe japanese thai indian fr...   \n",
       "2  health care proffesional tell way traumatising...   \n",
       "3  started reading one bathtub get id gotten fina...   \n",
       "4  really like book time everyone want equality s...   \n",
       "\n",
       "                                  summarized_reviews         0         1  \\\n",
       "0  susan cooper dark rising sequence joined pryda...  0.635252 -0.269045   \n",
       "1  sheer diversity recipe japanese thai indian fr...  0.261072  0.044054   \n",
       "2  health care proffesional tell way traumatising...  0.257239  0.295282   \n",
       "3  started reading one bathtub get id gotten fina...  0.683657 -0.247198   \n",
       "4  really like book time everyone want equality s...  0.492497  0.233496   \n",
       "\n",
       "          2         3         4         5  ...        10        11        12  \\\n",
       "0  0.012184 -0.010487  0.058941  0.251971  ... -0.184776 -0.035200 -0.052860   \n",
       "1  0.130190  0.080427 -0.001261  0.046605  ... -0.078350 -0.052345  0.057356   \n",
       "2  0.238382  0.178325 -0.077830  0.070369  ... -0.021567  0.065485  0.269843   \n",
       "3  0.033077  0.060875 -0.078793 -0.056407  ...  0.039104 -0.121871  0.087071   \n",
       "4  0.105420  0.168974  0.087518 -0.126515  ... -0.033602 -0.117381 -0.153551   \n",
       "\n",
       "         13        14        15        16        17        18        19  \n",
       "0  0.074156 -0.033203  0.029792  0.076104  0.132746  0.045042  0.031042  \n",
       "1  0.110849  0.248279 -0.254497  0.029056  0.108632  0.106938  0.194251  \n",
       "2  0.109493  0.062807 -0.056614  0.152163 -0.151631 -0.050819  0.159799  \n",
       "3  0.013348  0.125837  0.046312 -0.081648  0.077465 -0.085890 -0.125254  \n",
       "4 -0.093654  0.013880  0.031424  0.073882 -0.089763 -0.055060 -0.027179  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dimensionality Reduction\n",
    "# Set the desired number of components\n",
    "n_components = 20\n",
    "\n",
    "# Initialize TruncatedSVD and fit-transform the embeddings\n",
    "svd = TruncatedSVD(n_components=n_components)\n",
    "reduced_embeddings = svd.fit_transform(embeddings_df)\n",
    "\n",
    "# Convert the reduced embeddings to a DataFrame\n",
    "reduced_embeddings_df = pd.DataFrame(reduced_embeddings)\n",
    "\n",
    "# Concatenate the original data with the reduced embeddings\n",
    "vectorized_data = pd.concat([sample_data, reduced_embeddings_df], axis=1)\n",
    "vectorized_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "fdbcf0fe-a198-463f-ab76-be007dd68973",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_data.to_csv('data/vectorized_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "7ec4eb19-4c9e-49ec-b308-ec1bad252f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.6693\n"
     ]
    }
   ],
   "source": [
    "# Finding Similarity and calculate RMSE \n",
    "\n",
    "# the relevant features start from the 4th column onwards (0-indexed)\n",
    "features = vectorized_data.iloc[:, 4:]\n",
    "\n",
    "# Step 1: Standardize the feature set\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Step 2: Split the data into training and testing sets\n",
    "train_data, test_data = train_test_split(vectorized_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reset indices for easier access\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "test_data = test_data.reset_index(drop=True)\n",
    "\n",
    "# Select vector features from the training data\n",
    "train_vector_features = scaled_features[train_data.index]\n",
    "\n",
    "# Calculate cosine similarity matrix for training data\n",
    "cosine_sim = cosine_similarity(train_vector_features)\n",
    "\n",
    "# Initialize a list to store the predicted ratings\n",
    "predicted_ratings = []\n",
    "\n",
    "# Step 4: Loop over each item in the test set to predict its rating\n",
    "for idx, row in test_data.iterrows():\n",
    "    # Extract the index of the current test item\n",
    "    test_index = row.name  # Get the original index in the dataset\n",
    "    \n",
    "    # Compute similarity between the test item and all training items\n",
    "    similarity_scores = cosine_sim[test_index, :]\n",
    "\n",
    "    # Get the indices of the top 5 most similar training items\n",
    "    similar_indices = np.argsort(similarity_scores)[::-1][:5]  # Top 5\n",
    "    \n",
    "    # Retrieve the ratings of these similar training items\n",
    "    similar_ratings = train_data.iloc[similar_indices]['average_rating']\n",
    "    \n",
    "    # Retrieve the corresponding similarity scores\n",
    "    similar_sim_scores = similarity_scores[similar_indices]\n",
    "    \n",
    "    # Compute the weighted average to predict the rating\n",
    "    if np.sum(similar_sim_scores) == 0:\n",
    "        # If similarity scores sum to zero, default to the mean rating of the training set\n",
    "        predicted_rating = train_data['average_rating'].mean()\n",
    "    else:\n",
    "        predicted_rating = np.dot(similar_sim_scores, similar_ratings) / np.sum(similar_sim_scores)\n",
    "    \n",
    "    # Append the predicted rating to the list\n",
    "    predicted_ratings.append(predicted_rating)\n",
    "\n",
    "# Add the predicted ratings to the test DataFrame\n",
    "test_data['predicted_rating'] = predicted_ratings\n",
    "\n",
    "# Step 5: Calculate RMSE on the test set\n",
    "rmse = round(np.sqrt(mean_squared_error(test_data['average_rating'], test_data['predicted_rating'])),4)\n",
    "print(f\"Test RMSE: {rmse}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "38bf7c32-c2a1-4e60-8ee6-63dfb1382dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.4971\n"
     ]
    }
   ],
   "source": [
    "# calculate RMSE for the training set \n",
    "train_predictions = []\n",
    "for idx, row in train_data.iterrows():\n",
    "    # Extract the index of the current train item\n",
    "    train_index = row.name  # Get the original index in the dataset\n",
    "    \n",
    "    # Compute similarity between the train item and all training items\n",
    "    similarity_scores = cosine_sim[train_index, :]\n",
    "\n",
    "    # Get the indices of the top 5 most similar training items\n",
    "    similar_indices = np.argsort(similarity_scores)[::-1][:5]  # Top 5\n",
    "    \n",
    "    # Retrieve the ratings of these similar training items\n",
    "    similar_ratings = train_data.iloc[similar_indices]['average_rating']\n",
    "    \n",
    "    # Retrieve the corresponding similarity scores\n",
    "    similar_sim_scores = similarity_scores[similar_indices]\n",
    "    \n",
    "    # Compute the weighted average to predict the rating\n",
    "    if np.sum(similar_sim_scores) == 0:\n",
    "        predicted_rating = train_data['average_rating'].mean()\n",
    "    else:\n",
    "        predicted_rating = np.dot(similar_sim_scores, similar_ratings) / np.sum(similar_sim_scores)\n",
    "    \n",
    "    # Append the predicted rating to the list\n",
    "    train_predictions.append(predicted_rating)\n",
    "\n",
    "# Add the predicted ratings to the train DataFrame\n",
    "train_data['predicted_rating'] = train_predictions\n",
    "\n",
    "# Calculate RMSE on the training set\n",
    "train_rmse = round(np.sqrt(mean_squared_error(train_data['average_rating'], train_data['predicted_rating'])),4)\n",
    "print(f\"Train RMSE: {train_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "a7cf33da-d61b-4478-addc-f85a9487cf63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     product_id  average_rating\n",
      "352  0345413350        4.526316\n",
      "870  0451166582        4.428571\n",
      "927  0505523892        3.636364\n",
      "104  0064406970        4.666667\n",
      "763  0440995779        4.142857\n"
     ]
    }
   ],
   "source": [
    "def get_similar_products(product_id, top_n=5):\n",
    "    # Find the index of the given product ID\n",
    "    product_idx = vectorized_data_reduced[vectorized_data_reduced['product_id'] == product_id].index[0]\n",
    "    \n",
    "    # Get the similarity scores for this product\n",
    "    similarity_scores = cosine_sim[product_idx]\n",
    "    \n",
    "    # Get the indices of the most similar products, excluding the product itself\n",
    "    similar_indices = np.argsort(similarity_scores)[::-1][1:top_n + 1]\n",
    "    \n",
    "    # Get the similar products' details\n",
    "    similar_products = vectorized_data_reduced.iloc[similar_indices][['product_id', 'average_rating']]\n",
    "    \n",
    "    return similar_products\n",
    "\n",
    "# Example usage: Predict similar products for a given product ID\n",
    "similar_products = get_similar_products('0020425651', top_n=5)\n",
    "print(similar_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "a2d6caf4-5027-4b23-8288-681e08f2beb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_sentiment_data = vectorized_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "ea8b40f5-5284-458f-b4ce-f5d2778ce7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>aggregated_reviews</th>\n",
       "      <th>summarized_reviews</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0020425651</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>susan cooper dark rising sequence joined pryda...</td>\n",
       "      <td>susan cooper dark rising sequence joined pryda...</td>\n",
       "      <td>0.635252</td>\n",
       "      <td>-0.269045</td>\n",
       "      <td>0.012184</td>\n",
       "      <td>-0.010487</td>\n",
       "      <td>0.058941</td>\n",
       "      <td>0.251971</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052860</td>\n",
       "      <td>0.074156</td>\n",
       "      <td>-0.033203</td>\n",
       "      <td>0.029792</td>\n",
       "      <td>0.076104</td>\n",
       "      <td>0.132746</td>\n",
       "      <td>0.045042</td>\n",
       "      <td>0.031042</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.998871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0028610105</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>sheer diversity recipe japanese thai indian fr...</td>\n",
       "      <td>sheer diversity recipe japanese thai indian fr...</td>\n",
       "      <td>0.261072</td>\n",
       "      <td>0.044054</td>\n",
       "      <td>0.130190</td>\n",
       "      <td>0.080427</td>\n",
       "      <td>-0.001261</td>\n",
       "      <td>0.046605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057356</td>\n",
       "      <td>0.110849</td>\n",
       "      <td>0.248279</td>\n",
       "      <td>-0.254497</td>\n",
       "      <td>0.029056</td>\n",
       "      <td>0.108632</td>\n",
       "      <td>0.106938</td>\n",
       "      <td>0.194251</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.975348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>006001203X</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>health care proffesional tell way traumatising...</td>\n",
       "      <td>health care proffesional tell way traumatising...</td>\n",
       "      <td>0.257239</td>\n",
       "      <td>0.295282</td>\n",
       "      <td>0.238382</td>\n",
       "      <td>0.178325</td>\n",
       "      <td>-0.077830</td>\n",
       "      <td>0.070369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269843</td>\n",
       "      <td>0.109493</td>\n",
       "      <td>0.062807</td>\n",
       "      <td>-0.056614</td>\n",
       "      <td>0.152163</td>\n",
       "      <td>-0.151631</td>\n",
       "      <td>-0.050819</td>\n",
       "      <td>0.159799</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.997175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0060096195</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>started reading one bathtub get id gotten fina...</td>\n",
       "      <td>started reading one bathtub get id gotten fina...</td>\n",
       "      <td>0.683657</td>\n",
       "      <td>-0.247198</td>\n",
       "      <td>0.033077</td>\n",
       "      <td>0.060875</td>\n",
       "      <td>-0.078793</td>\n",
       "      <td>-0.056407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087071</td>\n",
       "      <td>0.013348</td>\n",
       "      <td>0.125837</td>\n",
       "      <td>0.046312</td>\n",
       "      <td>-0.081648</td>\n",
       "      <td>0.077465</td>\n",
       "      <td>-0.085890</td>\n",
       "      <td>-0.125254</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.993411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>006016848X</td>\n",
       "      <td>3.562500</td>\n",
       "      <td>really like book time everyone want equality s...</td>\n",
       "      <td>really like book time everyone want equality s...</td>\n",
       "      <td>0.492497</td>\n",
       "      <td>0.233496</td>\n",
       "      <td>0.105420</td>\n",
       "      <td>0.168974</td>\n",
       "      <td>0.087518</td>\n",
       "      <td>-0.126515</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.153551</td>\n",
       "      <td>-0.093654</td>\n",
       "      <td>0.013880</td>\n",
       "      <td>0.031424</td>\n",
       "      <td>0.073882</td>\n",
       "      <td>-0.089763</td>\n",
       "      <td>-0.055060</td>\n",
       "      <td>-0.027179</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.977043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  average_rating  \\\n",
       "0  0020425651        5.000000   \n",
       "1  0028610105        4.400000   \n",
       "2  006001203X        4.100000   \n",
       "3  0060096195        4.428571   \n",
       "4  006016848X        3.562500   \n",
       "\n",
       "                                  aggregated_reviews  \\\n",
       "0  susan cooper dark rising sequence joined pryda...   \n",
       "1  sheer diversity recipe japanese thai indian fr...   \n",
       "2  health care proffesional tell way traumatising...   \n",
       "3  started reading one bathtub get id gotten fina...   \n",
       "4  really like book time everyone want equality s...   \n",
       "\n",
       "                                  summarized_reviews         0         1  \\\n",
       "0  susan cooper dark rising sequence joined pryda...  0.635252 -0.269045   \n",
       "1  sheer diversity recipe japanese thai indian fr...  0.261072  0.044054   \n",
       "2  health care proffesional tell way traumatising...  0.257239  0.295282   \n",
       "3  started reading one bathtub get id gotten fina...  0.683657 -0.247198   \n",
       "4  really like book time everyone want equality s...  0.492497  0.233496   \n",
       "\n",
       "          2         3         4         5  ...        12        13        14  \\\n",
       "0  0.012184 -0.010487  0.058941  0.251971  ... -0.052860  0.074156 -0.033203   \n",
       "1  0.130190  0.080427 -0.001261  0.046605  ...  0.057356  0.110849  0.248279   \n",
       "2  0.238382  0.178325 -0.077830  0.070369  ...  0.269843  0.109493  0.062807   \n",
       "3  0.033077  0.060875 -0.078793 -0.056407  ...  0.087071  0.013348  0.125837   \n",
       "4  0.105420  0.168974  0.087518 -0.126515  ... -0.153551 -0.093654  0.013880   \n",
       "\n",
       "         15        16        17        18        19  sentiment  \\\n",
       "0  0.029792  0.076104  0.132746  0.045042  0.031042   POSITIVE   \n",
       "1 -0.254497  0.029056  0.108632  0.106938  0.194251   POSITIVE   \n",
       "2 -0.056614  0.152163 -0.151631 -0.050819  0.159799   NEGATIVE   \n",
       "3  0.046312 -0.081648  0.077465 -0.085890 -0.125254   POSITIVE   \n",
       "4  0.031424  0.073882 -0.089763 -0.055060 -0.027179   NEGATIVE   \n",
       "\n",
       "   sentiment_score  \n",
       "0         0.998871  \n",
       "1         0.975348  \n",
       "2         0.997175  \n",
       "3         0.993411  \n",
       "4         0.977043  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load a pre-trained sentiment analysis model\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Function to get sentiment\n",
    "def get_sentiment(review):\n",
    "    result = sentiment_pipeline(review)[0]\n",
    "    return result['label'], result['score']\n",
    "\n",
    "# Apply the function to summarize the reviews\n",
    "vectorized_sentiment_data[['sentiment', 'sentiment_score']] = vectorized_sentiment_data['summarized_reviews'].apply(get_sentiment).apply(pd.Series)\n",
    "vectorized_sentiment_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "698eb460-32e1-46bc-a350-fc0630ee411c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>aggregated_reviews</th>\n",
       "      <th>summarized_reviews</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0020425651</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>susan cooper dark rising sequence joined pryda...</td>\n",
       "      <td>susan cooper dark rising sequence joined pryda...</td>\n",
       "      <td>0.635252</td>\n",
       "      <td>-0.269045</td>\n",
       "      <td>0.012184</td>\n",
       "      <td>-0.010487</td>\n",
       "      <td>0.058941</td>\n",
       "      <td>0.251971</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052860</td>\n",
       "      <td>0.074156</td>\n",
       "      <td>-0.033203</td>\n",
       "      <td>0.029792</td>\n",
       "      <td>0.076104</td>\n",
       "      <td>0.132746</td>\n",
       "      <td>0.045042</td>\n",
       "      <td>0.031042</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0028610105</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>sheer diversity recipe japanese thai indian fr...</td>\n",
       "      <td>sheer diversity recipe japanese thai indian fr...</td>\n",
       "      <td>0.261072</td>\n",
       "      <td>0.044054</td>\n",
       "      <td>0.130190</td>\n",
       "      <td>0.080427</td>\n",
       "      <td>-0.001261</td>\n",
       "      <td>0.046605</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057356</td>\n",
       "      <td>0.110849</td>\n",
       "      <td>0.248279</td>\n",
       "      <td>-0.254497</td>\n",
       "      <td>0.029056</td>\n",
       "      <td>0.108632</td>\n",
       "      <td>0.106938</td>\n",
       "      <td>0.194251</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>006001203X</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>health care proffesional tell way traumatising...</td>\n",
       "      <td>health care proffesional tell way traumatising...</td>\n",
       "      <td>0.257239</td>\n",
       "      <td>0.295282</td>\n",
       "      <td>0.238382</td>\n",
       "      <td>0.178325</td>\n",
       "      <td>-0.077830</td>\n",
       "      <td>0.070369</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269843</td>\n",
       "      <td>0.109493</td>\n",
       "      <td>0.062807</td>\n",
       "      <td>-0.056614</td>\n",
       "      <td>0.152163</td>\n",
       "      <td>-0.151631</td>\n",
       "      <td>-0.050819</td>\n",
       "      <td>0.159799</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.997175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0060096195</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>started reading one bathtub get id gotten fina...</td>\n",
       "      <td>started reading one bathtub get id gotten fina...</td>\n",
       "      <td>0.683657</td>\n",
       "      <td>-0.247198</td>\n",
       "      <td>0.033077</td>\n",
       "      <td>0.060875</td>\n",
       "      <td>-0.078793</td>\n",
       "      <td>-0.056407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.087071</td>\n",
       "      <td>0.013348</td>\n",
       "      <td>0.125837</td>\n",
       "      <td>0.046312</td>\n",
       "      <td>-0.081648</td>\n",
       "      <td>0.077465</td>\n",
       "      <td>-0.085890</td>\n",
       "      <td>-0.125254</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>006016848X</td>\n",
       "      <td>3.562500</td>\n",
       "      <td>really like book time everyone want equality s...</td>\n",
       "      <td>really like book time everyone want equality s...</td>\n",
       "      <td>0.492497</td>\n",
       "      <td>0.233496</td>\n",
       "      <td>0.105420</td>\n",
       "      <td>0.168974</td>\n",
       "      <td>0.087518</td>\n",
       "      <td>-0.126515</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.153551</td>\n",
       "      <td>-0.093654</td>\n",
       "      <td>0.013880</td>\n",
       "      <td>0.031424</td>\n",
       "      <td>0.073882</td>\n",
       "      <td>-0.089763</td>\n",
       "      <td>-0.055060</td>\n",
       "      <td>-0.027179</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.977043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  average_rating  \\\n",
       "0  0020425651        5.000000   \n",
       "1  0028610105        4.400000   \n",
       "2  006001203X        4.100000   \n",
       "3  0060096195        4.428571   \n",
       "4  006016848X        3.562500   \n",
       "\n",
       "                                  aggregated_reviews  \\\n",
       "0  susan cooper dark rising sequence joined pryda...   \n",
       "1  sheer diversity recipe japanese thai indian fr...   \n",
       "2  health care proffesional tell way traumatising...   \n",
       "3  started reading one bathtub get id gotten fina...   \n",
       "4  really like book time everyone want equality s...   \n",
       "\n",
       "                                  summarized_reviews         0         1  \\\n",
       "0  susan cooper dark rising sequence joined pryda...  0.635252 -0.269045   \n",
       "1  sheer diversity recipe japanese thai indian fr...  0.261072  0.044054   \n",
       "2  health care proffesional tell way traumatising...  0.257239  0.295282   \n",
       "3  started reading one bathtub get id gotten fina...  0.683657 -0.247198   \n",
       "4  really like book time everyone want equality s...  0.492497  0.233496   \n",
       "\n",
       "          2         3         4         5  ...        12        13        14  \\\n",
       "0  0.012184 -0.010487  0.058941  0.251971  ... -0.052860  0.074156 -0.033203   \n",
       "1  0.130190  0.080427 -0.001261  0.046605  ...  0.057356  0.110849  0.248279   \n",
       "2  0.238382  0.178325 -0.077830  0.070369  ...  0.269843  0.109493  0.062807   \n",
       "3  0.033077  0.060875 -0.078793 -0.056407  ...  0.087071  0.013348  0.125837   \n",
       "4  0.105420  0.168974  0.087518 -0.126515  ... -0.153551 -0.093654  0.013880   \n",
       "\n",
       "         15        16        17        18        19  sentiment  \\\n",
       "0  0.029792  0.076104  0.132746  0.045042  0.031042          1   \n",
       "1 -0.254497  0.029056  0.108632  0.106938  0.194251          1   \n",
       "2 -0.056614  0.152163 -0.151631 -0.050819  0.159799         -1   \n",
       "3  0.046312 -0.081648  0.077465 -0.085890 -0.125254          1   \n",
       "4  0.031424  0.073882 -0.089763 -0.055060 -0.027179         -1   \n",
       "\n",
       "   sentiment_score  \n",
       "0         0.998871  \n",
       "1         0.975348  \n",
       "2         0.997175  \n",
       "3         0.993411  \n",
       "4         0.977043  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_mapping = {\n",
    "    'POSITIVE': 1,\n",
    "    'NEGATIVE': -1,\n",
    "    'NEUTRAL': 0  \n",
    "}\n",
    "vectorized_sentiment_data['sentiment'] = vectorized_sentiment_data['sentiment'].map(sentiment_mapping)\n",
    "vectorized_sentiment_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "id": "a31e23cf-f859-4a86-b91f-35f36d01c114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure all column names are strings\n",
    "vectorized_sentiment_data.columns = vectorized_sentiment_data.columns.astype(str)\n",
    "\n",
    "# Step 1: Standardize the feature set\n",
    "features_sentiment = vectorized_sentiment_data.iloc[:, 4:]  \n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "ff99ad5e-cf04-4b21-8a9b-2ad784e8bf27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train RMSE: 0.6721\n",
      "Test RMSE: 0.687\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Ensure all column names are strings\n",
    "# vectorized_data_reduced.columns = vectorized_sentiment_data.columns.astype(str)\n",
    "\n",
    "# # Step 1: Standardize the feature set\n",
    "# features = vectorized_sentiment_data.iloc[:, 4:]  \n",
    "# scaler = StandardScaler()\n",
    "# scaled_features = scaler.fit_transform(features)\n",
    "\n",
    "# Step 2: Split the data into training and testing sets\n",
    "train_data, test_data = train_test_split(vectorized_sentiment_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reset indices for easier access\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "test_data = test_data.reset_index(drop=True)\n",
    "\n",
    "# Select vector features from the training data\n",
    "train_vector_features = scaled_features[train_data.index]\n",
    "test_vector_features = scaled_features[test_data.index]\n",
    "\n",
    "# Calculate cosine similarity matrix for training data\n",
    "cosine_sim_train = cosine_similarity(train_vector_features)\n",
    "\n",
    "# Step 3: Predict ratings for the train set\n",
    "predicted_ratings_train = []\n",
    "for idx, row in train_data.iterrows():\n",
    "    # Compute similarity between the current training item and all other training items\n",
    "    similarity_scores = cosine_sim_train[idx, :]\n",
    "    \n",
    "    # Get the indices of the top 5 most similar training items, excluding the item itself\n",
    "    similar_indices = np.argsort(similarity_scores)[::-1][1:6]\n",
    "    \n",
    "    # Retrieve the ratings of these similar training items\n",
    "    similar_ratings = train_data.iloc[similar_indices]['average_rating']\n",
    "    similar_sim_scores = similarity_scores[similar_indices]\n",
    "    \n",
    "    # Compute the weighted average to predict the rating\n",
    "    if np.sum(similar_sim_scores) == 0:\n",
    "        predicted_rating = train_data['average_rating'].mean()\n",
    "    else:\n",
    "        predicted_rating = np.dot(similar_sim_scores, similar_ratings) / np.sum(similar_sim_scores)\n",
    "    \n",
    "    predicted_ratings_train.append(predicted_rating)\n",
    "\n",
    "# Calculate RMSE for training set\n",
    "train_rmse = round(np.sqrt(mean_squared_error(train_data['average_rating'], predicted_ratings_train)), 4)\n",
    "print(f\"Train RMSE: {train_rmse}\")\n",
    "\n",
    "# Step 4: Predict ratings for the test set using the similarity matrix of training data\n",
    "cosine_sim_test = cosine_similarity(test_vector_features, train_vector_features)\n",
    "predicted_ratings_test = []\n",
    "for idx, row in test_data.iterrows():\n",
    "    # Compute similarity between the current test item and all training items\n",
    "    similarity_scores = cosine_sim_test[idx, :]\n",
    "    \n",
    "    # Get the indices of the top 5 most similar training items\n",
    "    similar_indices = np.argsort(similarity_scores)[::-1][:5]\n",
    "    \n",
    "    # Retrieve the ratings of these similar training items\n",
    "    similar_ratings = train_data.iloc[similar_indices]['average_rating']\n",
    "    similar_sim_scores = similarity_scores[similar_indices]\n",
    "    \n",
    "    # Compute the weighted average to predict the rating\n",
    "    if np.sum(similar_sim_scores) == 0:\n",
    "        predicted_rating = train_data['average_rating'].mean()\n",
    "    else:\n",
    "        predicted_rating = np.dot(similar_sim_scores, similar_ratings) / np.sum(similar_sim_scores)\n",
    "    \n",
    "    predicted_ratings_test.append(predicted_rating)\n",
    "\n",
    "# Calculate RMSE for test set\n",
    "test_rmse = round(np.sqrt(mean_squared_error(test_data['average_rating'], predicted_ratings_test)), 4)\n",
    "print(f\"Test RMSE: {test_rmse}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d59b8b7-031d-4a5a-8d21-b4f47c572005",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:563]",
   "language": "python",
   "name": "conda-env-563-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
