{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eec1218-5ab8-4639-8adf-b5a969693d9d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "## Introduction\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6dbf6a5c-6590-4378-bdb9-b3c912dbf0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hashlib import sha1\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from surprise import SVD\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b961be-5f3c-4426-ab30-15b14a53cacc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "## Data Description<a name=\"2\"></a>\n",
    "Given the large size of the dataset, only 10000 rows of the dataset is used for the models.\n",
    "This project utilizes a comprehensive dataset sourced from Kaggle, which can be accessed via the following link: (https://www.kaggle.com/datasets/beaglelee/amazon-reviews-us-books-v1-02-tsv-zip). The dataset consists of 15 columns and encompasses a substantial total of 3,105,370 rows, providing rich insights into customer feedback and product ratings specifically within the book category.\n",
    "\n",
    "Due to the extensive size of the dataset, a subset of 10,000 rows has been selected for analysis and modeling. This reduction allows for efficient processing while still capturing the diverse range of reviews and ratings present in the original dataset.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7bbe7833-717b-4df6-8ea4-8f3b2f147ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "data = pd.read_csv(\"data/amazon_reviews_us_Books_v1_02.tsv\", sep='\\t', on_bad_lines='skip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bf3228b3-7f08-4f8e-a746-7abd2473b066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>12076615</td>\n",
       "      <td>RQ58W7SMO911M</td>\n",
       "      <td>0385730586</td>\n",
       "      <td>122662979</td>\n",
       "      <td>Sisterhood of the Traveling Pants (Book 1)</td>\n",
       "      <td>Books</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>this book was a great learning novel!</td>\n",
       "      <td>this boook was a great one that you could lear...</td>\n",
       "      <td>2005-10-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>12703090</td>\n",
       "      <td>RF6IUKMGL8SF</td>\n",
       "      <td>0811828964</td>\n",
       "      <td>56191234</td>\n",
       "      <td>The Bad Girl's Guide to Getting What You Want</td>\n",
       "      <td>Books</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Fun Fluff</td>\n",
       "      <td>If you are looking for something to stimulate ...</td>\n",
       "      <td>2005-10-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>12257412</td>\n",
       "      <td>R1DOSHH6AI622S</td>\n",
       "      <td>1844161560</td>\n",
       "      <td>253182049</td>\n",
       "      <td>Eisenhorn (A Warhammer 40,000 Omnibus)</td>\n",
       "      <td>Books</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>this isn't a review</td>\n",
       "      <td>never read it-a young relative idicated he lik...</td>\n",
       "      <td>2005-10-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>50732546</td>\n",
       "      <td>RATOTLA3OF70O</td>\n",
       "      <td>0373836635</td>\n",
       "      <td>348672532</td>\n",
       "      <td>Colby Conspiracy (Colby Agency)</td>\n",
       "      <td>Books</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>fine author on her A-game</td>\n",
       "      <td>Though she is honored to be Chicago Woman of t...</td>\n",
       "      <td>2005-10-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>51964897</td>\n",
       "      <td>R1TNWRKIVHVYOV</td>\n",
       "      <td>0262181533</td>\n",
       "      <td>598678717</td>\n",
       "      <td>The Psychology of Proof: Deductive Reasoning i...</td>\n",
       "      <td>Books</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Execellent cursor examination</td>\n",
       "      <td>Review based on a cursory examination by Unive...</td>\n",
       "      <td>2005-10-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "0          US     12076615   RQ58W7SMO911M  0385730586       122662979   \n",
       "1          US     12703090    RF6IUKMGL8SF  0811828964        56191234   \n",
       "2          US     12257412  R1DOSHH6AI622S  1844161560       253182049   \n",
       "3          US     50732546   RATOTLA3OF70O  0373836635       348672532   \n",
       "4          US     51964897  R1TNWRKIVHVYOV  0262181533       598678717   \n",
       "\n",
       "                                       product_title product_category  \\\n",
       "0         Sisterhood of the Traveling Pants (Book 1)            Books   \n",
       "1      The Bad Girl's Guide to Getting What You Want            Books   \n",
       "2             Eisenhorn (A Warhammer 40,000 Omnibus)            Books   \n",
       "3                    Colby Conspiracy (Colby Agency)            Books   \n",
       "4  The Psychology of Proof: Deductive Reasoning i...            Books   \n",
       "\n",
       "   star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "0          4.0            2.0          3.0    N                 N   \n",
       "1          3.0            5.0          5.0    N                 N   \n",
       "2          4.0            1.0         22.0    N                 N   \n",
       "3          5.0            2.0          2.0    N                 N   \n",
       "4          4.0            0.0          2.0    N                 N   \n",
       "\n",
       "                         review_headline  \\\n",
       "0  this book was a great learning novel!   \n",
       "1                              Fun Fluff   \n",
       "2                    this isn't a review   \n",
       "3              fine author on her A-game   \n",
       "4          Execellent cursor examination   \n",
       "\n",
       "                                         review_body review_date  \n",
       "0  this boook was a great one that you could lear...  2005-10-14  \n",
       "1  If you are looking for something to stimulate ...  2005-10-14  \n",
       "2  never read it-a young relative idicated he lik...  2005-10-14  \n",
       "3  Though she is honored to be Chicago Woman of t...  2005-10-14  \n",
       "4  Review based on a cursory examination by Unive...  2005-10-14  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5e2f95-f813-4cd3-879c-34b3d3f9cfc1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "## Exploratory Data Analysis(EDA) <a name=\"3\"></a>\n",
    "\n",
    "This section describes the exploratory data analysis (EDA) techniques employed to derive valuable insights from the dataset, which will inform the subsequent stages of model development.\n",
    "\n",
    "To create a targeted subset for analysis, we identified product IDs and customer IDs associated with at least 100 reviews. This filtering process resulted in a dataset containing 24,466 rows, representing customer reviews. Our final subset includes 1,672 distinct products and 1,230 distinct customers, ensuring a diverse representation of both products and customers. This comprehensive approach enables us to conduct a thorough examination of customer feedback, facilitating deeper insights into their preferences and behaviors.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bf4c5e63-e457-4f53-ba53-3b7d23e0686e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3105370 entries, 0 to 3105369\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   marketplace        object \n",
      " 1   customer_id        int64  \n",
      " 2   review_id          object \n",
      " 3   product_id         object \n",
      " 4   product_parent     int64  \n",
      " 5   product_title      object \n",
      " 6   product_category   object \n",
      " 7   star_rating        float64\n",
      " 8   helpful_votes      float64\n",
      " 9   total_votes        float64\n",
      " 10  vine               object \n",
      " 11  verified_purchase  object \n",
      " 12  review_headline    object \n",
      " 13  review_body        object \n",
      " 14  review_date        object \n",
      "dtypes: float64(3), int64(2), object(10)\n",
      "memory usage: 355.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bcb0bdf6-8c2d-409f-9640-e625aefc7f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marketplace            0\n",
       "customer_id            0\n",
       "review_id              0\n",
       "product_id             0\n",
       "product_parent         0\n",
       "product_title          0\n",
       "product_category       0\n",
       "star_rating            4\n",
       "helpful_votes          4\n",
       "total_votes            4\n",
       "vine                   4\n",
       "verified_purchase      4\n",
       "review_headline       57\n",
       "review_body            4\n",
       "review_date          133\n",
       "dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ed0a5f88-14af-4fd4-baf2-b22a8cd3c122",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bd566ae0-7c36-40be-b983-4456e5c79188",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace(['null', 'N/A', '', ' '], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f8c3e030-ec22-4e02-9572-303fde59d229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marketplace          0\n",
       "customer_id          0\n",
       "review_id            0\n",
       "product_id           0\n",
       "product_parent       0\n",
       "product_title        0\n",
       "product_category     0\n",
       "star_rating          0\n",
       "helpful_votes        0\n",
       "total_votes          0\n",
       "vine                 0\n",
       "verified_purchase    0\n",
       "review_headline      0\n",
       "review_body          0\n",
       "review_date          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "56ec071b-1471-4a84-adbf-8353cfa1f418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marketplace                1\n",
       "customer_id          1502265\n",
       "review_id            3105184\n",
       "product_id            779692\n",
       "product_parent        666003\n",
       "product_title         713665\n",
       "product_category           1\n",
       "star_rating                5\n",
       "helpful_votes            942\n",
       "total_votes             1024\n",
       "vine                       2\n",
       "verified_purchase          2\n",
       "review_headline      2456998\n",
       "review_body          3070458\n",
       "review_date             3575\n",
       "dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ee6755d9-ce24-4a8d-9a66-c8f580c147d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24466, 15)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selected a subset with customers and products with at least 100 reviews\n",
    "# Step 1: Filter customers with at least 100 reviews\n",
    "customer_review_counts = data.groupby('customer_id').size().reset_index(name='review_count')\n",
    "customers_with_at_least_100_reviews = customer_review_counts[customer_review_counts['review_count'] >= 100]\n",
    "\n",
    "# Step 2: Filter products with at least 100 reviews\n",
    "product_review_counts = data.groupby('product_id').size().reset_index(name='review_count')\n",
    "products_with_at_least_100_reviews = product_review_counts[product_review_counts['review_count'] >= 100]\n",
    "\n",
    "# Step 3: Filter the original dataset to only include customers and products with at least 100 reviews\n",
    "filtered_data = data[\n",
    "    (data['customer_id'].isin(customers_with_at_least_100_reviews['customer_id'])) &\n",
    "    (data['product_id'].isin(products_with_at_least_100_reviews['product_id']))\n",
    "]\n",
    "filtered_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "64c9e215-042b-45e3-be92-6d84b8400d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data.to_csv('data/amazon_reviews_subset_100.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f3c23737-7b42-4942-8e8e-7b819d3d22a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marketplace              1\n",
       "customer_id           1230\n",
       "review_id            24466\n",
       "product_id            1672\n",
       "product_parent        1485\n",
       "product_title         1562\n",
       "product_category         1\n",
       "star_rating              5\n",
       "helpful_votes          423\n",
       "total_votes            460\n",
       "vine                     1\n",
       "verified_purchase        2\n",
       "review_headline      23305\n",
       "review_body          24314\n",
       "review_date           2574\n",
       "dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961a5e36-f4fd-45b6-8c43-6740dc262019",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "## Collaborative Filtering\n",
    "**Collaborative Filtering** is a widely-used technique for addressing the challenge of missing entries in a utility matrix, leveraging user behavior and interactions to make recommendations. This approach operates on the principle that users who have agreed in the past will continue to agree in the future, allowing the model to infer preferences based on the preferences of similar users.\n",
    "\n",
    "This method can be likened to advanced dimensionality reduction techniques such as Latent Semantic Analysis (LSA) or Truncated Singular Value Decomposition (SVD). By capturing the underlying relationships between users and items, collaborative filtering helps to predict missing values, enhancing the accuracy and relevance of recommendations.\n",
    "\n",
    "In this project, we will implement collaborative filtering as our baseline model to improve user experience by personalizing content based on historical data, thus enabling more informed decision-making.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "491d78cb-beef-48db-88bc-ddfb95474efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50230169</td>\n",
       "      <td>0451526341</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50776149</td>\n",
       "      <td>038551428X</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12598621</td>\n",
       "      <td>059035342X</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49770667</td>\n",
       "      <td>1594480001</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49828549</td>\n",
       "      <td>0671027360</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  product_id  star_rating\n",
       "0     50230169  0451526341          4.0\n",
       "1     50776149  038551428X          5.0\n",
       "2     12598621  059035342X          5.0\n",
       "3     49770667  1594480001          5.0\n",
       "4     49828549  0671027360          1.0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the data\n",
    "coll_data = filtered_data[['customer_id', 'product_id', 'star_rating']].reset_index(drop=True)\n",
    "coll_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "742f1968-46bc-490b-b7be-6a68094e4ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of customers (N)  : 1230\n",
      "Number of products (M) : 1672\n"
     ]
    }
   ],
   "source": [
    "# Number of customers and products\n",
    "user_key = \"customer_id\"\n",
    "item_key = \"product_id\"\n",
    "N = len(np.unique(coll_data[user_key])) \n",
    "M = len(np.unique(coll_data[item_key]))\n",
    "print(f\"Number of customers (N)  : {N}\")\n",
    "print(f\"Number of products (M) : {M}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "070d7eb1-ed77-4bba-b44b-f8fd9a0086dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-nan ratings percentage: 1.19\n"
     ]
    }
   ],
   "source": [
    "non_nan_ratings_percentage = (len(coll_data) / (N * M) * 100) \n",
    "print(f\"Non-nan ratings percentage: {np.round(non_nan_ratings_percentage,3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3ca5bd28-648d-4812-923c-1b97f4b711fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of ratings per customer : 19.89\n",
      "Average number of ratings per product: 14.63\n"
     ]
    }
   ],
   "source": [
    "avg_nratings_per_user = coll_data.groupby(user_key).size().mean()\n",
    "avg_nratings_per_movie = coll_data.groupby(item_key).size().mean()\n",
    "print(f\"Average number of ratings per customer : {avg_nratings_per_user:.2f}\")\n",
    "print(f\"Average number of ratings per product: {avg_nratings_per_movie:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "01a72bc1-78c6-4ead-b28b-abb0a17873a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Splitting\n",
    "X = coll_data.copy()\n",
    "y = coll_data['customer_id']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b70bb14a-b22d-4283-9d34-67b59d96b3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mapper = dict(zip(np.unique(coll_data[user_key]), list(range(N))))\n",
    "item_mapper = dict(zip(np.unique(coll_data[item_key]), list(range(M))))\n",
    "user_inverse_mapper = dict(zip(list(range(N)), np.unique(coll_data[user_key])))\n",
    "item_inverse_mapper = dict(zip(list(range(M)), np.unique(coll_data[item_key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c030f351-d414-410f-a4e2-be5ae058f3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Y_from_ratings(data, N, M):\n",
    "    Y = np.zeros((N, M))\n",
    "    Y.fill(np.nan)\n",
    "    for index, val in data.iterrows():\n",
    "        n = user_mapper[val[user_key]]\n",
    "        m = item_mapper[val[item_key]]\n",
    "        Y[n, m] = val[\"star_rating\"]\n",
    "\n",
    "    return Y\n",
    "\n",
    "train_mat = create_Y_from_ratings(X_train, N, M)\n",
    "valid_mat = create_Y_from_ratings(X_valid, N, M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0446201b-ba26-4bdb-8006-f9852b0d56e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-nan elements in train_mat: 19085\n",
      "Number of non-nan elements in valid_mat: 4855\n"
     ]
    }
   ],
   "source": [
    "# What's the number of non-nan elements in train_mat (nnn_train_mat)?\n",
    "nnn_train_mat = np.sum(~np.isnan(train_mat)) \n",
    "\n",
    "# What's the number of non-nan elements in valid_mat (nnn_valid_mat)?\n",
    "nnn_valid_mat = np.sum(~np.isnan(valid_mat)) \n",
    "print(f\"Number of non-nan elements in train_mat: {nnn_train_mat}\")\n",
    "print(f\"Number of non-nan elements in valid_mat: {nnn_valid_mat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "329bf88f-8133-49e8-823a-a03c2e5022c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "def error(Y1, Y2):\n",
    "    \"\"\"\n",
    "    Given two matrices of the same shape, \n",
    "    returns the root mean squared error (RMSE).\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.nanmean((Y1 - Y2) ** 2))\n",
    "\n",
    "\n",
    "def evaluate(pred_Y, train_mat, valid_mat, model_name=\"Global average\"):\n",
    "    \"\"\"\n",
    "    Given predicted utility matrix and train and validation utility matrices \n",
    "    print train and validation RMSEs.\n",
    "    \"\"\"\n",
    "    print(\"%s train RMSE: %0.2f\" % (model_name, error(pred_Y, train_mat)))\n",
    "    print(\"%s valid RMSE: %0.2f\" % (model_name, error(pred_Y, valid_mat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0a2c14fa-0053-4ff2-b3a5-6fd4aa05b08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global average train RMSE: 1.07\n",
      "Global average valid RMSE: 1.06\n"
     ]
    }
   ],
   "source": [
    "# global average rating baseline\n",
    "avg = np.nanmean(train_mat)\n",
    "pred_g = np.zeros(train_mat.shape) + avg\n",
    "evaluate(pred_g, train_mat, valid_mat, model_name=\"Global average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "bfc44586-a17a-4aef-864d-a370f729bf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-user average train RMSE: 0.95\n",
      "Per-user average valid RMSE: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j6/44dd1c8s33xg2kn35nxq3f5m0000gn/T/ipykernel_48949/2152599090.py:2: RuntimeWarning: Mean of empty slice\n",
      "  avg_n = np.nanmean(train_mat, axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Per-user average baseline\n",
    "avg_n = np.nanmean(train_mat, axis=1)\n",
    "avg_n[\n",
    "    np.isnan(avg_n)\n",
    "] = avg  \n",
    "pred_n = np.tile(avg_n[:, None], (1, M))\n",
    "evaluate(pred_n, train_mat, valid_mat, model_name=\"Per-user average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "681a3704-cc72-433d-a3d1-83c1844c1563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-product average train RMSE: 0.94\n",
      "Per-product average valid RMSE: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j6/44dd1c8s33xg2kn35nxq3f5m0000gn/T/ipykernel_48949/1388612677.py:2: RuntimeWarning: Mean of empty slice\n",
      "  avg_m = np.nanmean(train_mat, axis=0)\n"
     ]
    }
   ],
   "source": [
    "# Per-product average baseline\n",
    "avg_m = np.nanmean(train_mat, axis=0)\n",
    "avg_m[np.isnan(avg_m)] = avg\n",
    "pred_m = np.tile(avg_m[None, :], (N, 1))\n",
    "evaluate(pred_m, train_mat, valid_mat, model_name=\"Per-product average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ff5925cb-82d4-40de-ac29-dfdc496ceafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-user and product average train RMSE: 0.89\n",
      "Per-user and product average valid RMSE: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Average of per-user and per-product average baselines\n",
    "pred_n_m = (pred_n + pred_m) * 0.5\n",
    "evaluate(pred_n_m, train_mat, valid_mat, model_name=\"Per-user and product average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "705bb771-a661-4c89-9c40-909caf601848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of neighbours:  10\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 1.05\n",
      "\n",
      "Number of neighbours:  15\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 1.05\n",
      "\n",
      "Number of neighbours:  18\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 1.05\n",
      "\n",
      "Number of neighbours:  20\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 1.05\n",
      "\n",
      "Number of neighbours:  40\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 1.05\n"
     ]
    }
   ],
   "source": [
    "# K-nearest neighbours imputation\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "num_neighs = [10, 15, 18, 20, 40]\n",
    "for n_neighbors in num_neighs:\n",
    "    print(\"\\nNumber of neighbours: \", n_neighbors)\n",
    "    imputer = KNNImputer(n_neighbors=n_neighbors, keep_empty_features=True)\n",
    "    pred_knn = imputer.fit_transform(train_mat)\n",
    "    evaluate(pred_knn, train_mat, valid_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3294ab37-5558-4fed-ab30-8f9d1aac7ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TruncatedSVD (k = 10) train RMSE: 0.83\n",
      "TruncatedSVD (k = 10) valid RMSE: 0.96\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 50) train RMSE: 0.69\n",
      "TruncatedSVD (k = 50) valid RMSE: 0.95\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 100) train RMSE: 0.57\n",
      "TruncatedSVD (k = 100) valid RMSE: 0.95\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 200) train RMSE: 0.41\n",
      "TruncatedSVD (k = 200) valid RMSE: 0.95\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 500) train RMSE: 0.15\n",
      "TruncatedSVD (k = 500) valid RMSE: 0.95\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 1000) train RMSE: 0.01\n",
      "TruncatedSVD (k = 1000) valid RMSE: 0.95\n"
     ]
    }
   ],
   "source": [
    "# collaborative filtering with TruncatedSVD()\n",
    "def reconstruct_svd(Z, W, avg_n, avg_m):\n",
    "    return Z @ W + 0.5 * avg_n[:, None] + 0.5 * avg_m[None]\n",
    "\n",
    "\n",
    "train_mat_svd = train_mat - 0.5 * avg_n[:, None] - 0.5 * avg_m[None]\n",
    "train_mat_svd = np.nan_to_num(train_mat_svd)\n",
    "\n",
    "k_range = [10, 50, 100, 200, 500, 1000]\n",
    "for k in k_range:\n",
    "    print(\"\\n\")\n",
    "    tsvd = TruncatedSVD(n_components=k)\n",
    "    Z = tsvd.fit_transform(train_mat_svd)\n",
    "    W = tsvd.components_\n",
    "    X_hat = reconstruct_svd(Z, W, avg_n, avg_m)\n",
    "    evaluate(X_hat, train_mat, valid_mat, model_name=\"TruncatedSVD (k = %d)\" % k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e24b2cfc-a3ce-43ea-927c-750370cab260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using surprise package\n",
    "reader = Reader()\n",
    "data = Dataset.load_from_df(coll_data, reader)  \n",
    "\n",
    "k = 10\n",
    "algo = SVD(n_factors=k, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "869fb9dd-5ae1-4a3b-b638-f34bb774cf7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9232  0.9419  0.9577  0.9425  0.9740  0.9479  0.0170  \n",
      "Fit time          0.04    0.02    0.02    0.02    0.02    0.03    0.01    \n",
      "Test time         0.01    0.01    0.01    0.01    0.01    0.01    0.00    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.923235</td>\n",
       "      <td>0.039560</td>\n",
       "      <td>0.010284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.941899</td>\n",
       "      <td>0.023084</td>\n",
       "      <td>0.008132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.957692</td>\n",
       "      <td>0.022823</td>\n",
       "      <td>0.008161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.942477</td>\n",
       "      <td>0.022872</td>\n",
       "      <td>0.008036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.974015</td>\n",
       "      <td>0.022733</td>\n",
       "      <td>0.007917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_rmse  fit_time  test_time\n",
       "0   0.923235  0.039560   0.010284\n",
       "1   0.941899  0.023084   0.008132\n",
       "2   0.957692  0.022823   0.008161\n",
       "3   0.942477  0.022872   0.008036\n",
       "4   0.974015  0.022733   0.007917"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cross_validate(algo, data, measures=[\"RMSE\"], cv=5, verbose=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fdfa40-c5a4-4ee7-8b63-9cb1c031c7e4",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "## Incorporating Reviews\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "1c5663cd-1d87-40b4-bcce-33393f8206e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50230169</td>\n",
       "      <td>0451526341</td>\n",
       "      <td>4.0</td>\n",
       "      <td>A generation ago, the sight of the cover of Ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50776149</td>\n",
       "      <td>038551428X</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The most interesting thing about this book is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12598621</td>\n",
       "      <td>059035342X</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Even though this is the shortest book in the H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49770667</td>\n",
       "      <td>1594480001</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Well I thoroughly enjoyed this book. Although ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49828549</td>\n",
       "      <td>0671027360</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Early in this novel, our hero finds out that a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  product_id  star_rating  \\\n",
       "0     50230169  0451526341          4.0   \n",
       "1     50776149  038551428X          5.0   \n",
       "2     12598621  059035342X          5.0   \n",
       "3     49770667  1594480001          5.0   \n",
       "4     49828549  0671027360          1.0   \n",
       "\n",
       "                                         review_body  \n",
       "0  A generation ago, the sight of the cover of Ge...  \n",
       "1  The most interesting thing about this book is ...  \n",
       "2  Even though this is the shortest book in the H...  \n",
       "3  Well I thoroughly enjoyed this book. Although ...  \n",
       "4  Early in this novel, our hero finds out that a...  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_data = filtered_data[['customer_id', 'product_id', 'star_rating', 'review_body']].reset_index(drop=True)\n",
    "review_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "a9d0ce39-eb3e-403a-bc96-1063b6b9cb5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>aggregated_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0020425651</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>susan cooper dark rising sequence joined pryda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0028610105</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>sheer diversity recipe japanese thai indian fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>006001203X</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>health care proffesional tell way traumatising...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0060096195</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>started reading one bathtub get id gotten fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>006016848X</td>\n",
       "      <td>3.562500</td>\n",
       "      <td>really like book time everyone want equality s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  average_rating  \\\n",
       "0  0020425651        5.000000   \n",
       "1  0028610105        4.400000   \n",
       "2  006001203X        4.100000   \n",
       "3  0060096195        4.428571   \n",
       "4  006016848X        3.562500   \n",
       "\n",
       "                                  aggregated_reviews  \n",
       "0  susan cooper dark rising sequence joined pryda...  \n",
       "1  sheer diversity recipe japanese thai indian fr...  \n",
       "2  health care proffesional tell way traumatising...  \n",
       "3  started reading one bathtub get id gotten fina...  \n",
       "4  really like book time everyone want equality s...  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean the reviews\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "# Initialize stopwords and lemmatizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation and special characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Remove stopwords and lemmatize\n",
    "    text = ' '.join(lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words)\n",
    "    return text\n",
    "\n",
    "# Clean the 'review_body' column\n",
    "review_data['cleaned_review_body'] = review_data['review_body'].apply(clean_text)\n",
    "\n",
    "# Step 1: Group by 'product_id' and aggregate\n",
    "aggregated_data = review_data.groupby('product_id').agg(\n",
    "    average_rating=('star_rating', 'mean'),         # Mean of the star ratings\n",
    "    aggregated_reviews=('cleaned_review_body', ' '.join)  # Concatenate all cleaned review bodies\n",
    ").reset_index()\n",
    "\n",
    "# Display the aggregated DataFrame\n",
    "aggregated_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "546a89ea-eb08-4054-ac6d-30e4898c5b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer\n",
    "\n",
    "# Load the BART model and tokenizer\n",
    "model_name = \"facebook/bart-large-cnn\"\n",
    "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
    "model = BartForConditionalGeneration.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "58c0d1cd-207f-453d-83a5-7d5378727c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/monorouzi/miniconda3/envs/563/lib/python3.11/site-packages/transformers/generation/utils.py:1158: UserWarning: Unfeasible length constraints: `min_length` (56) is larger than the maximum possible length (50). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>summarized_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0020425651</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>susan cooper dark rising sequence joined pryda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0028610105</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>sheer diversity recipe japanese thai indian fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>006001203X</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>health care proffesional tell way traumatising...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0060096195</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>started reading one bathtub get id gotten fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>006016848X</td>\n",
       "      <td>3.562500</td>\n",
       "      <td>really like book time everyone want equality s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0060175400</td>\n",
       "      <td>4.076923</td>\n",
       "      <td>book one read day atleast reader story greates...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0060187239</td>\n",
       "      <td>4.222222</td>\n",
       "      <td>mr winik good job describing event april may f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0060191988</td>\n",
       "      <td>2.285714</td>\n",
       "      <td>maybe one metaphor book fresh rest cliched stu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0060193395</td>\n",
       "      <td>4.176471</td>\n",
       "      <td>youll see lot criticism page people havent tri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>006019491X</td>\n",
       "      <td>3.777778</td>\n",
       "      <td>isabel allende written epic amp enthralling ad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  average_rating  \\\n",
       "0  0020425651        5.000000   \n",
       "1  0028610105        4.400000   \n",
       "2  006001203X        4.100000   \n",
       "3  0060096195        4.428571   \n",
       "4  006016848X        3.562500   \n",
       "5  0060175400        4.076923   \n",
       "6  0060187239        4.222222   \n",
       "7  0060191988        2.285714   \n",
       "8  0060193395        4.176471   \n",
       "9  006019491X        3.777778   \n",
       "\n",
       "                                  summarized_reviews  \n",
       "0  susan cooper dark rising sequence joined pryda...  \n",
       "1  sheer diversity recipe japanese thai indian fr...  \n",
       "2  health care proffesional tell way traumatising...  \n",
       "3  started reading one bathtub get id gotten fina...  \n",
       "4  really like book time everyone want equality s...  \n",
       "5  book one read day atleast reader story greates...  \n",
       "6  mr winik good job describing event april may f...  \n",
       "7  maybe one metaphor book fresh rest cliched stu...  \n",
       "8  youll see lot criticism page people havent tri...  \n",
       "9  isabel allende written epic amp enthralling ad...  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def summarize_reviews(df):\n",
    "    summaries = []\n",
    "    for review in df['aggregated_reviews']:\n",
    "        inputs = tokenizer(review, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "        summary_ids = model.generate(inputs[\"input_ids\"], max_length=50, num_beams=4, early_stopping=True)\n",
    "        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        summaries.append(summary)\n",
    "    return summaries\n",
    "\n",
    "# Summarizing the first 10 reviews and assigning only to those rows\n",
    "aggregated_data.loc[0:9, 'summarized_reviews'] = summarize_reviews(aggregated_data[0:10])\n",
    "\n",
    "aggregated_data[['product_id','average_rating', 'summarized_reviews']][0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "582e645f-cc72-466a-8b84-88058830bed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data= aggregated_data[['product_id','average_rating', 'summarized_reviews']][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "28ecfc96-c663-4aa0-9493-cca3cbbf6609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>summarized_reviews</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>...</th>\n",
       "      <th>374</th>\n",
       "      <th>375</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0020425651</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>susan cooper dark rising sequence joined pryda...</td>\n",
       "      <td>-0.070799</td>\n",
       "      <td>-0.061837</td>\n",
       "      <td>-0.003631</td>\n",
       "      <td>0.012133</td>\n",
       "      <td>-0.035551</td>\n",
       "      <td>0.093195</td>\n",
       "      <td>-0.016502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065155</td>\n",
       "      <td>0.053727</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>0.088892</td>\n",
       "      <td>-0.042067</td>\n",
       "      <td>0.041044</td>\n",
       "      <td>0.070728</td>\n",
       "      <td>-0.043085</td>\n",
       "      <td>-0.064512</td>\n",
       "      <td>0.038242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0028610105</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>sheer diversity recipe japanese thai indian fr...</td>\n",
       "      <td>-0.073018</td>\n",
       "      <td>-0.023593</td>\n",
       "      <td>0.066772</td>\n",
       "      <td>0.036159</td>\n",
       "      <td>0.006666</td>\n",
       "      <td>-0.010815</td>\n",
       "      <td>0.028194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042942</td>\n",
       "      <td>0.037886</td>\n",
       "      <td>-0.001067</td>\n",
       "      <td>-0.009074</td>\n",
       "      <td>0.065551</td>\n",
       "      <td>-0.054624</td>\n",
       "      <td>0.067726</td>\n",
       "      <td>0.079832</td>\n",
       "      <td>-0.015437</td>\n",
       "      <td>-0.041357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>006001203X</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>health care proffesional tell way traumatising...</td>\n",
       "      <td>0.004559</td>\n",
       "      <td>0.033951</td>\n",
       "      <td>0.020969</td>\n",
       "      <td>0.073957</td>\n",
       "      <td>-0.022270</td>\n",
       "      <td>0.056416</td>\n",
       "      <td>0.097014</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005109</td>\n",
       "      <td>0.098458</td>\n",
       "      <td>0.004446</td>\n",
       "      <td>0.010148</td>\n",
       "      <td>-0.050168</td>\n",
       "      <td>0.036669</td>\n",
       "      <td>0.133147</td>\n",
       "      <td>0.013290</td>\n",
       "      <td>0.063390</td>\n",
       "      <td>0.043042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0060096195</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>started reading one bathtub get id gotten fina...</td>\n",
       "      <td>-0.066638</td>\n",
       "      <td>-0.083743</td>\n",
       "      <td>0.053587</td>\n",
       "      <td>0.066727</td>\n",
       "      <td>-0.009095</td>\n",
       "      <td>0.022768</td>\n",
       "      <td>0.044251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046725</td>\n",
       "      <td>0.029233</td>\n",
       "      <td>0.014859</td>\n",
       "      <td>0.084216</td>\n",
       "      <td>-0.085885</td>\n",
       "      <td>0.048461</td>\n",
       "      <td>0.023749</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>-0.075700</td>\n",
       "      <td>-0.034523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>006016848X</td>\n",
       "      <td>3.562500</td>\n",
       "      <td>really like book time everyone want equality s...</td>\n",
       "      <td>-0.061388</td>\n",
       "      <td>0.048214</td>\n",
       "      <td>0.015069</td>\n",
       "      <td>-0.003492</td>\n",
       "      <td>-0.092024</td>\n",
       "      <td>0.022740</td>\n",
       "      <td>0.012945</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041296</td>\n",
       "      <td>0.018716</td>\n",
       "      <td>0.018985</td>\n",
       "      <td>0.015178</td>\n",
       "      <td>-0.019459</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.134094</td>\n",
       "      <td>-0.078086</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>-0.001025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 387 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  average_rating  \\\n",
       "0  0020425651        5.000000   \n",
       "1  0028610105        4.400000   \n",
       "2  006001203X        4.100000   \n",
       "3  0060096195        4.428571   \n",
       "4  006016848X        3.562500   \n",
       "\n",
       "                                  summarized_reviews         0         1  \\\n",
       "0  susan cooper dark rising sequence joined pryda... -0.070799 -0.061837   \n",
       "1  sheer diversity recipe japanese thai indian fr... -0.073018 -0.023593   \n",
       "2  health care proffesional tell way traumatising...  0.004559  0.033951   \n",
       "3  started reading one bathtub get id gotten fina... -0.066638 -0.083743   \n",
       "4  really like book time everyone want equality s... -0.061388  0.048214   \n",
       "\n",
       "          2         3         4         5         6  ...       374       375  \\\n",
       "0 -0.003631  0.012133 -0.035551  0.093195 -0.016502  ...  0.065155  0.053727   \n",
       "1  0.066772  0.036159  0.006666 -0.010815  0.028194  ...  0.042942  0.037886   \n",
       "2  0.020969  0.073957 -0.022270  0.056416  0.097014  ... -0.005109  0.098458   \n",
       "3  0.053587  0.066727 -0.009095  0.022768  0.044251  ...  0.046725  0.029233   \n",
       "4  0.015069 -0.003492 -0.092024  0.022740  0.012945  ...  0.041296  0.018716   \n",
       "\n",
       "        376       377       378       379       380       381       382  \\\n",
       "0  0.003597  0.088892 -0.042067  0.041044  0.070728 -0.043085 -0.064512   \n",
       "1 -0.001067 -0.009074  0.065551 -0.054624  0.067726  0.079832 -0.015437   \n",
       "2  0.004446  0.010148 -0.050168  0.036669  0.133147  0.013290  0.063390   \n",
       "3  0.014859  0.084216 -0.085885  0.048461  0.023749  0.003057 -0.075700   \n",
       "4  0.018985  0.015178 -0.019459  0.000856  0.134094 -0.078086  0.004868   \n",
       "\n",
       "        383  \n",
       "0  0.038242  \n",
       "1 -0.041357  \n",
       "2  0.043042  \n",
       "3 -0.034523  \n",
       "4 -0.001025  \n",
       "\n",
       "[5 rows x 387 columns]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load a pre-trained model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2') \n",
    "\n",
    "# Encode the summaries to get embeddings\n",
    "embeddings = model.encode(sample_data['summarized_reviews'].tolist())\n",
    "\n",
    "# Convert embeddings to a DataFrame\n",
    "embeddings_df = pd.DataFrame(embeddings)\n",
    "\n",
    "vectorized_data = pd.concat([sample_data, embeddings_df], axis=1)\n",
    "vectorized_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "ea8b40f5-5284-458f-b4ce-f5d2778ce7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>summarized_reviews</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0020425651</td>\n",
       "      <td>susan cooper dark rising sequence joined pryda...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.998871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0028610105</td>\n",
       "      <td>sheer diversity recipe japanese thai indian fr...</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.975348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>006001203X</td>\n",
       "      <td>health care proffesional tell way traumatising...</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.997175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0060096195</td>\n",
       "      <td>started reading one bathtub get id gotten fina...</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.993411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>006016848X</td>\n",
       "      <td>really like book time everyone want equality s...</td>\n",
       "      <td>3.562500</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.977043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id                                 summarized_reviews  \\\n",
       "0  0020425651  susan cooper dark rising sequence joined pryda...   \n",
       "1  0028610105  sheer diversity recipe japanese thai indian fr...   \n",
       "2  006001203X  health care proffesional tell way traumatising...   \n",
       "3  0060096195  started reading one bathtub get id gotten fina...   \n",
       "4  006016848X  really like book time everyone want equality s...   \n",
       "\n",
       "   average_rating sentiment  sentiment_score  \n",
       "0        5.000000  POSITIVE         0.998871  \n",
       "1        4.400000  POSITIVE         0.975348  \n",
       "2        4.100000  NEGATIVE         0.997175  \n",
       "3        4.428571  POSITIVE         0.993411  \n",
       "4        3.562500  NEGATIVE         0.977043  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load a pre-trained sentiment analysis model\n",
    "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Function to get sentiment\n",
    "def get_sentiment(review):\n",
    "    result = sentiment_pipeline(review)[0]\n",
    "    return result['label'], result['score']\n",
    "\n",
    "# Apply the function to summarize the reviews\n",
    "sample_data[['sentiment', 'sentiment_score']] = sample_data['summarized_reviews'].apply(get_sentiment).apply(pd.Series)\n",
    "sample_data[['product_id', 'summarized_reviews','average_rating', 'sentiment', 'sentiment_score']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "698eb460-32e1-46bc-a350-fc0630ee411c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>summarized_reviews</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>joy</th>\n",
       "      <th>anger</th>\n",
       "      <th>fear</th>\n",
       "      <th>sadness</th>\n",
       "      <th>sentiment_numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0020425651</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>susan cooper dark rising sequence joined pryda...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998871</td>\n",
       "      <td>0.997277</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0028610105</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>sheer diversity recipe japanese thai indian fr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975348</td>\n",
       "      <td>0.998141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>006001203X</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>health care proffesional tell way traumatising...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.997175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0060096195</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>started reading one bathtub get id gotten fina...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.528073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>006016848X</td>\n",
       "      <td>3.562500</td>\n",
       "      <td>really like book time everyone want equality s...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.977043</td>\n",
       "      <td>0.982340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  average_rating  \\\n",
       "0  0020425651        5.000000   \n",
       "1  0028610105        4.400000   \n",
       "2  006001203X        4.100000   \n",
       "3  0060096195        4.428571   \n",
       "4  006016848X        3.562500   \n",
       "\n",
       "                                  summarized_reviews  sentiment  \\\n",
       "0  susan cooper dark rising sequence joined pryda...          1   \n",
       "1  sheer diversity recipe japanese thai indian fr...          1   \n",
       "2  health care proffesional tell way traumatising...         -1   \n",
       "3  started reading one bathtub get id gotten fina...          1   \n",
       "4  really like book time everyone want equality s...         -1   \n",
       "\n",
       "   sentiment_score       joy     anger      fear  sadness  sentiment_numeric  \n",
       "0         0.998871  0.997277       NaN       NaN      NaN                  1  \n",
       "1         0.975348  0.998141       NaN       NaN      NaN                  1  \n",
       "2         0.997175       NaN  0.972973       NaN      NaN                 -1  \n",
       "3         0.993411       NaN       NaN  0.528073      NaN                  1  \n",
       "4         0.977043  0.982340       NaN       NaN      NaN                 -1  "
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_mapping = {\n",
    "    'POSITIVE': 1,\n",
    "    'NEGATIVE': -1,\n",
    "    'NEUTRAL': 0  \n",
    "}\n",
    "sample_data['sentiment'] = sample_data['sentiment'].map(sentiment_mapping)\n",
    "sample_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "e5629642-1290-445d-a91c-552f7ecc2e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>summarized_reviews</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>joy</th>\n",
       "      <th>anger</th>\n",
       "      <th>fear</th>\n",
       "      <th>sadness</th>\n",
       "      <th>sentiment_numeric</th>\n",
       "      <th>joy</th>\n",
       "      <th>anger</th>\n",
       "      <th>fear</th>\n",
       "      <th>sadness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0020425651</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>susan cooper dark rising sequence joined pryda...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998871</td>\n",
       "      <td>0.997277</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997277</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0028610105</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>sheer diversity recipe japanese thai indian fr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975348</td>\n",
       "      <td>0.998141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>006001203X</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>health care proffesional tell way traumatising...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.997175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0060096195</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>started reading one bathtub get id gotten fina...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.528073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.528073</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>006016848X</td>\n",
       "      <td>3.562500</td>\n",
       "      <td>really like book time everyone want equality s...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.977043</td>\n",
       "      <td>0.982340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.982340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  average_rating  \\\n",
       "0  0020425651        5.000000   \n",
       "1  0028610105        4.400000   \n",
       "2  006001203X        4.100000   \n",
       "3  0060096195        4.428571   \n",
       "4  006016848X        3.562500   \n",
       "\n",
       "                                  summarized_reviews  sentiment  \\\n",
       "0  susan cooper dark rising sequence joined pryda...          1   \n",
       "1  sheer diversity recipe japanese thai indian fr...          1   \n",
       "2  health care proffesional tell way traumatising...         -1   \n",
       "3  started reading one bathtub get id gotten fina...          1   \n",
       "4  really like book time everyone want equality s...         -1   \n",
       "\n",
       "   sentiment_score       joy     anger      fear  sadness  sentiment_numeric  \\\n",
       "0         0.998871  0.997277       NaN       NaN      NaN                  1   \n",
       "1         0.975348  0.998141       NaN       NaN      NaN                  1   \n",
       "2         0.997175       NaN  0.972973       NaN      NaN                 -1   \n",
       "3         0.993411       NaN       NaN  0.528073      NaN                  1   \n",
       "4         0.977043  0.982340       NaN       NaN      NaN                 -1   \n",
       "\n",
       "        joy     anger      fear  sadness  \n",
       "0  0.997277       NaN       NaN      NaN  \n",
       "1  0.998141       NaN       NaN      NaN  \n",
       "2       NaN  0.972973       NaN      NaN  \n",
       "3       NaN       NaN  0.528073      NaN  \n",
       "4  0.982340       NaN       NaN      NaN  "
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load a pre-trained emotion analysis model\n",
    "emotion_pipeline = pipeline(\"text-classification\", model=\"bhadresh-savani/bert-base-uncased-emotion\")\n",
    "\n",
    "# Function to get emotions\n",
    "def get_emotions(review):\n",
    "    result = emotion_pipeline(review)\n",
    "    return {emotion['label']: emotion['score'] for emotion in result}\n",
    "\n",
    "# Apply the function to get emotions\n",
    "emotion_df = sample_data['summarized_reviews'].apply(get_emotions).apply(pd.Series)\n",
    "\n",
    "# Join the emotion features back to the original DataFrame\n",
    "sample_data = pd.concat([sample_data, emotion_df], axis=1)\n",
    "sample_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "4983e127-ebc0-4ba9-bfcf-30d8820ae11b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>summarized_reviews</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>joy</th>\n",
       "      <th>anger</th>\n",
       "      <th>fear</th>\n",
       "      <th>sadness</th>\n",
       "      <th>sentiment_numeric</th>\n",
       "      <th>...</th>\n",
       "      <th>374</th>\n",
       "      <th>375</th>\n",
       "      <th>376</th>\n",
       "      <th>377</th>\n",
       "      <th>378</th>\n",
       "      <th>379</th>\n",
       "      <th>380</th>\n",
       "      <th>381</th>\n",
       "      <th>382</th>\n",
       "      <th>383</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0020425651</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>susan cooper dark rising sequence joined pryda...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998871</td>\n",
       "      <td>0.997277</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065155</td>\n",
       "      <td>0.053727</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>0.088892</td>\n",
       "      <td>-0.042067</td>\n",
       "      <td>0.041044</td>\n",
       "      <td>0.070728</td>\n",
       "      <td>-0.043085</td>\n",
       "      <td>-0.064512</td>\n",
       "      <td>0.038242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0028610105</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>sheer diversity recipe japanese thai indian fr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975348</td>\n",
       "      <td>0.998141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042942</td>\n",
       "      <td>0.037886</td>\n",
       "      <td>-0.001067</td>\n",
       "      <td>-0.009074</td>\n",
       "      <td>0.065551</td>\n",
       "      <td>-0.054624</td>\n",
       "      <td>0.067726</td>\n",
       "      <td>0.079832</td>\n",
       "      <td>-0.015437</td>\n",
       "      <td>-0.041357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>006001203X</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>health care proffesional tell way traumatising...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.997175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.972973</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005109</td>\n",
       "      <td>0.098458</td>\n",
       "      <td>0.004446</td>\n",
       "      <td>0.010148</td>\n",
       "      <td>-0.050168</td>\n",
       "      <td>0.036669</td>\n",
       "      <td>0.133147</td>\n",
       "      <td>0.013290</td>\n",
       "      <td>0.063390</td>\n",
       "      <td>0.043042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0060096195</td>\n",
       "      <td>4.428571</td>\n",
       "      <td>started reading one bathtub get id gotten fina...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.993411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.528073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046725</td>\n",
       "      <td>0.029233</td>\n",
       "      <td>0.014859</td>\n",
       "      <td>0.084216</td>\n",
       "      <td>-0.085885</td>\n",
       "      <td>0.048461</td>\n",
       "      <td>0.023749</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>-0.075700</td>\n",
       "      <td>-0.034523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>006016848X</td>\n",
       "      <td>3.562500</td>\n",
       "      <td>really like book time everyone want equality s...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.977043</td>\n",
       "      <td>0.982340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041296</td>\n",
       "      <td>0.018716</td>\n",
       "      <td>0.018985</td>\n",
       "      <td>0.015178</td>\n",
       "      <td>-0.019459</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.134094</td>\n",
       "      <td>-0.078086</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>-0.001025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 394 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   product_id  average_rating  \\\n",
       "0  0020425651        5.000000   \n",
       "1  0028610105        4.400000   \n",
       "2  006001203X        4.100000   \n",
       "3  0060096195        4.428571   \n",
       "4  006016848X        3.562500   \n",
       "\n",
       "                                  summarized_reviews  sentiment  \\\n",
       "0  susan cooper dark rising sequence joined pryda...          1   \n",
       "1  sheer diversity recipe japanese thai indian fr...          1   \n",
       "2  health care proffesional tell way traumatising...         -1   \n",
       "3  started reading one bathtub get id gotten fina...          1   \n",
       "4  really like book time everyone want equality s...         -1   \n",
       "\n",
       "   sentiment_score       joy     anger      fear  sadness  sentiment_numeric  \\\n",
       "0         0.998871  0.997277       NaN       NaN      NaN                  1   \n",
       "1         0.975348  0.998141       NaN       NaN      NaN                  1   \n",
       "2         0.997175       NaN  0.972973       NaN      NaN                 -1   \n",
       "3         0.993411       NaN       NaN  0.528073      NaN                  1   \n",
       "4         0.977043  0.982340       NaN       NaN      NaN                 -1   \n",
       "\n",
       "   ...       374       375       376       377       378       379       380  \\\n",
       "0  ...  0.065155  0.053727  0.003597  0.088892 -0.042067  0.041044  0.070728   \n",
       "1  ...  0.042942  0.037886 -0.001067 -0.009074  0.065551 -0.054624  0.067726   \n",
       "2  ... -0.005109  0.098458  0.004446  0.010148 -0.050168  0.036669  0.133147   \n",
       "3  ...  0.046725  0.029233  0.014859  0.084216 -0.085885  0.048461  0.023749   \n",
       "4  ...  0.041296  0.018716  0.018985  0.015178 -0.019459  0.000856  0.134094   \n",
       "\n",
       "        381       382       383  \n",
       "0 -0.043085 -0.064512  0.038242  \n",
       "1  0.079832 -0.015437 -0.041357  \n",
       "2  0.013290  0.063390  0.043042  \n",
       "3  0.003057 -0.075700 -0.034523  \n",
       "4 -0.078086  0.004868 -0.001025  \n",
       "\n",
       "[5 rows x 394 columns]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reset index if needed\n",
    "vectorized_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Merge the vectors with the main DataFrame on 'product_id'\n",
    "aggregated_data_with_vectors = pd.concat([sample_data, vectorized_data], axis=1)\n",
    "aggregated_data_with_vectors = aggregated_data_with_vectors.loc[:, ~aggregated_data_with_vectors.columns.duplicated()]\n",
    "\n",
    "aggregated_data_with_vectors.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "8bb43862-f6b0-4bfe-9f49-08562891f8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "review_vectors = aggregated_data_with_vectors.iloc[:, 9:].values \n",
    "\n",
    "# Function to predict ratings based on cosine similarity\n",
    "def predict_ratings(aggregated_data_with_vectors, review_vectors):\n",
    "    predicted_ratings = []\n",
    "\n",
    "    # Calculate cosine similarity matrix\n",
    "    similarity_matrix = cosine_similarity(review_vectors)\n",
    "\n",
    "    for idx in range(len(aggregated_data_with_vectors)):\n",
    "        # Get similar products (excluding itself)\n",
    "        similar_indices = np.argsort(similarity_matrix[idx])[:-2:-1]  # Get top similar products (excluding self)\n",
    "        \n",
    "        # Get ratings of similar products\n",
    "        similar_ratings = aggregated_data_with_vectors.iloc[similar_indices]['average_rating']\n",
    "        \n",
    "        # Predict rating as the mean of similar products' ratings\n",
    "        if len(similar_ratings) > 0:\n",
    "            predicted_rating = similar_ratings.mean()\n",
    "        else:\n",
    "            predicted_rating = aggregated_data_with_vectors.iloc[idx]['average_rating']  # Fallback to the original rating\n",
    "        \n",
    "        predicted_ratings.append(predicted_rating)\n",
    "\n",
    "    return predicted_ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "0d27b705-5396-4580-b746-0f323aed0660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Predict ratings\n",
    "predicted_ratings = predict_ratings(aggregated_data_with_vectors, review_vectors)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(mean_squared_error(aggregated_data_with_vectors['average_rating'], predicted_ratings))\n",
    "print(f'RMSE: {rmse:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ec0208-59dd-4f72-9442-14c3941471d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:563]",
   "language": "python",
   "name": "conda-env-563-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
