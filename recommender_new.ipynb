{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0eec1218-5ab8-4639-8adf-b5a969693d9d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "## Introduction\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6dbf6a5c-6590-4378-bdb9-b3c912dbf0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hashlib import sha1\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from surprise import SVD\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b961be-5f3c-4426-ab30-15b14a53cacc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "## Data Description<a name=\"2\"></a>\n",
    "Given the large size of the dataset, only 10000 rows of the dataset is used for the models.\n",
    "This project utilizes a comprehensive dataset sourced from Kaggle, which can be accessed via the following link: (https://www.kaggle.com/datasets/beaglelee/amazon-reviews-us-books-v1-02-tsv-zip). The dataset consists of 15 columns and encompasses a substantial total of 3,105,370 rows, providing rich insights into customer feedback and product ratings specifically within the book category.\n",
    "\n",
    "Due to the extensive size of the dataset, a subset of 10,000 rows has been selected for analysis and modeling. This reduction allows for efficient processing while still capturing the diverse range of reviews and ratings present in the original dataset.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7bbe7833-717b-4df6-8ea4-8f3b2f147ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "data = pd.read_csv(\"data/amazon_reviews_us_Books_v1_02.tsv\", sep='\\t', on_bad_lines='skip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bf3228b3-7f08-4f8e-a746-7abd2473b066",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>12076615</td>\n",
       "      <td>RQ58W7SMO911M</td>\n",
       "      <td>0385730586</td>\n",
       "      <td>122662979</td>\n",
       "      <td>Sisterhood of the Traveling Pants (Book 1)</td>\n",
       "      <td>Books</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>this book was a great learning novel!</td>\n",
       "      <td>this boook was a great one that you could lear...</td>\n",
       "      <td>2005-10-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>12703090</td>\n",
       "      <td>RF6IUKMGL8SF</td>\n",
       "      <td>0811828964</td>\n",
       "      <td>56191234</td>\n",
       "      <td>The Bad Girl's Guide to Getting What You Want</td>\n",
       "      <td>Books</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Fun Fluff</td>\n",
       "      <td>If you are looking for something to stimulate ...</td>\n",
       "      <td>2005-10-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>12257412</td>\n",
       "      <td>R1DOSHH6AI622S</td>\n",
       "      <td>1844161560</td>\n",
       "      <td>253182049</td>\n",
       "      <td>Eisenhorn (A Warhammer 40,000 Omnibus)</td>\n",
       "      <td>Books</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>this isn't a review</td>\n",
       "      <td>never read it-a young relative idicated he lik...</td>\n",
       "      <td>2005-10-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>50732546</td>\n",
       "      <td>RATOTLA3OF70O</td>\n",
       "      <td>0373836635</td>\n",
       "      <td>348672532</td>\n",
       "      <td>Colby Conspiracy (Colby Agency)</td>\n",
       "      <td>Books</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>fine author on her A-game</td>\n",
       "      <td>Though she is honored to be Chicago Woman of t...</td>\n",
       "      <td>2005-10-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>51964897</td>\n",
       "      <td>R1TNWRKIVHVYOV</td>\n",
       "      <td>0262181533</td>\n",
       "      <td>598678717</td>\n",
       "      <td>The Psychology of Proof: Deductive Reasoning i...</td>\n",
       "      <td>Books</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>Execellent cursor examination</td>\n",
       "      <td>Review based on a cursory examination by Unive...</td>\n",
       "      <td>2005-10-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "0          US     12076615   RQ58W7SMO911M  0385730586       122662979   \n",
       "1          US     12703090    RF6IUKMGL8SF  0811828964        56191234   \n",
       "2          US     12257412  R1DOSHH6AI622S  1844161560       253182049   \n",
       "3          US     50732546   RATOTLA3OF70O  0373836635       348672532   \n",
       "4          US     51964897  R1TNWRKIVHVYOV  0262181533       598678717   \n",
       "\n",
       "                                       product_title product_category  \\\n",
       "0         Sisterhood of the Traveling Pants (Book 1)            Books   \n",
       "1      The Bad Girl's Guide to Getting What You Want            Books   \n",
       "2             Eisenhorn (A Warhammer 40,000 Omnibus)            Books   \n",
       "3                    Colby Conspiracy (Colby Agency)            Books   \n",
       "4  The Psychology of Proof: Deductive Reasoning i...            Books   \n",
       "\n",
       "   star_rating  helpful_votes  total_votes vine verified_purchase  \\\n",
       "0          4.0            2.0          3.0    N                 N   \n",
       "1          3.0            5.0          5.0    N                 N   \n",
       "2          4.0            1.0         22.0    N                 N   \n",
       "3          5.0            2.0          2.0    N                 N   \n",
       "4          4.0            0.0          2.0    N                 N   \n",
       "\n",
       "                         review_headline  \\\n",
       "0  this book was a great learning novel!   \n",
       "1                              Fun Fluff   \n",
       "2                    this isn't a review   \n",
       "3              fine author on her A-game   \n",
       "4          Execellent cursor examination   \n",
       "\n",
       "                                         review_body review_date  \n",
       "0  this boook was a great one that you could lear...  2005-10-14  \n",
       "1  If you are looking for something to stimulate ...  2005-10-14  \n",
       "2  never read it-a young relative idicated he lik...  2005-10-14  \n",
       "3  Though she is honored to be Chicago Woman of t...  2005-10-14  \n",
       "4  Review based on a cursory examination by Unive...  2005-10-14  "
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5e2f95-f813-4cd3-879c-34b3d3f9cfc1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "## Exploratory Data Analysis(EDA) <a name=\"3\"></a>\n",
    "\n",
    "This section describes the exploratory data analysis (EDA) techniques employed to derive valuable insights from the dataset, which will inform the subsequent stages of model development.\n",
    "\n",
    "To create a targeted subset for analysis, we identified product IDs and customer IDs associated with at least 100 reviews. This filtering process resulted in a dataset containing 24,466 rows, representing customer reviews. Our final subset includes 1,672 distinct products and 1,230 distinct customers, ensuring a diverse representation of both products and customers. This comprehensive approach enables us to conduct a thorough examination of customer feedback, facilitating deeper insights into their preferences and behaviors.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bf4c5e63-e457-4f53-ba53-3b7d23e0686e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3105370 entries, 0 to 3105369\n",
      "Data columns (total 15 columns):\n",
      " #   Column             Dtype  \n",
      "---  ------             -----  \n",
      " 0   marketplace        object \n",
      " 1   customer_id        int64  \n",
      " 2   review_id          object \n",
      " 3   product_id         object \n",
      " 4   product_parent     int64  \n",
      " 5   product_title      object \n",
      " 6   product_category   object \n",
      " 7   star_rating        float64\n",
      " 8   helpful_votes      float64\n",
      " 9   total_votes        float64\n",
      " 10  vine               object \n",
      " 11  verified_purchase  object \n",
      " 12  review_headline    object \n",
      " 13  review_body        object \n",
      " 14  review_date        object \n",
      "dtypes: float64(3), int64(2), object(10)\n",
      "memory usage: 355.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "bcb0bdf6-8c2d-409f-9640-e625aefc7f38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marketplace            0\n",
       "customer_id            0\n",
       "review_id              0\n",
       "product_id             0\n",
       "product_parent         0\n",
       "product_title          0\n",
       "product_category       0\n",
       "star_rating            4\n",
       "helpful_votes          4\n",
       "total_votes            4\n",
       "vine                   4\n",
       "verified_purchase      4\n",
       "review_headline       57\n",
       "review_body            4\n",
       "review_date          133\n",
       "dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ed0a5f88-14af-4fd4-baf2-b22a8cd3c122",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bd566ae0-7c36-40be-b983-4456e5c79188",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.replace(['null', 'N/A', '', ' '], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f8c3e030-ec22-4e02-9572-303fde59d229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marketplace          0\n",
       "customer_id          0\n",
       "review_id            0\n",
       "product_id           0\n",
       "product_parent       0\n",
       "product_title        0\n",
       "product_category     0\n",
       "star_rating          0\n",
       "helpful_votes        0\n",
       "total_votes          0\n",
       "vine                 0\n",
       "verified_purchase    0\n",
       "review_headline      0\n",
       "review_body          0\n",
       "review_date          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "56ec071b-1471-4a84-adbf-8353cfa1f418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marketplace                1\n",
       "customer_id          1502265\n",
       "review_id            3105184\n",
       "product_id            779692\n",
       "product_parent        666003\n",
       "product_title         713665\n",
       "product_category           1\n",
       "star_rating                5\n",
       "helpful_votes            942\n",
       "total_votes             1024\n",
       "vine                       2\n",
       "verified_purchase          2\n",
       "review_headline      2456998\n",
       "review_body          3070458\n",
       "review_date             3575\n",
       "dtype: int64"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ee6755d9-ce24-4a8d-9a66-c8f580c147d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24466, 15)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selected a subset with customers and products with at least 100 reviews\n",
    "# Step 1: Filter customers with at least 100 reviews\n",
    "customer_review_counts = data.groupby('customer_id').size().reset_index(name='review_count')\n",
    "customers_with_at_least_100_reviews = customer_review_counts[customer_review_counts['review_count'] >= 100]\n",
    "\n",
    "# Step 2: Filter products with at least 100 reviews\n",
    "product_review_counts = data.groupby('product_id').size().reset_index(name='review_count')\n",
    "products_with_at_least_100_reviews = product_review_counts[product_review_counts['review_count'] >= 100]\n",
    "\n",
    "# Step 3: Filter the original dataset to only include customers and products with at least 100 reviews\n",
    "filtered_data = data[\n",
    "    (data['customer_id'].isin(customers_with_at_least_100_reviews['customer_id'])) &\n",
    "    (data['product_id'].isin(products_with_at_least_100_reviews['product_id']))\n",
    "]\n",
    "filtered_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "64c9e215-042b-45e3-be92-6d84b8400d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data.to_csv('data/amazon_reviews_subset_100.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f3c23737-7b42-4942-8e8e-7b819d3d22a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marketplace              1\n",
       "customer_id           1230\n",
       "review_id            24466\n",
       "product_id            1672\n",
       "product_parent        1485\n",
       "product_title         1562\n",
       "product_category         1\n",
       "star_rating              5\n",
       "helpful_votes          423\n",
       "total_votes            460\n",
       "vine                     1\n",
       "verified_purchase        2\n",
       "review_headline      23305\n",
       "review_body          24314\n",
       "review_date           2574\n",
       "dtype: int64"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961a5e36-f4fd-45b6-8c43-6740dc262019",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "## Collaborative Filtering\n",
    "**Collaborative Filtering** is a widely-used technique for addressing the challenge of missing entries in a utility matrix, leveraging user behavior and interactions to make recommendations. This approach operates on the principle that users who have agreed in the past will continue to agree in the future, allowing the model to infer preferences based on the preferences of similar users.\n",
    "\n",
    "This method can be likened to advanced dimensionality reduction techniques such as Latent Semantic Analysis (LSA) or Truncated Singular Value Decomposition (SVD). By capturing the underlying relationships between users and items, collaborative filtering helps to predict missing values, enhancing the accuracy and relevance of recommendations.\n",
    "\n",
    "In this project, we will implement collaborative filtering as our baseline model to improve user experience by personalizing content based on historical data, thus enabling more informed decision-making.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "491d78cb-beef-48db-88bc-ddfb95474efd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>star_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50230169</td>\n",
       "      <td>0451526341</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50776149</td>\n",
       "      <td>038551428X</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12598621</td>\n",
       "      <td>059035342X</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49770667</td>\n",
       "      <td>1594480001</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49828549</td>\n",
       "      <td>0671027360</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  product_id  star_rating\n",
       "0     50230169  0451526341          4.0\n",
       "1     50776149  038551428X          5.0\n",
       "2     12598621  059035342X          5.0\n",
       "3     49770667  1594480001          5.0\n",
       "4     49828549  0671027360          1.0"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the data\n",
    "coll_data = filtered_data[['customer_id', 'product_id', 'star_rating']].reset_index(drop=True)\n",
    "coll_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "742f1968-46bc-490b-b7be-6a68094e4ed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of customers (N)  : 1230\n",
      "Number of products (M) : 1672\n"
     ]
    }
   ],
   "source": [
    "# Number of customers and products\n",
    "user_key = \"customer_id\"\n",
    "item_key = \"product_id\"\n",
    "N = len(np.unique(coll_data[user_key])) \n",
    "M = len(np.unique(coll_data[item_key]))\n",
    "print(f\"Number of customers (N)  : {N}\")\n",
    "print(f\"Number of products (M) : {M}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "070d7eb1-ed77-4bba-b44b-f8fd9a0086dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-nan ratings percentage: 1.19\n"
     ]
    }
   ],
   "source": [
    "non_nan_ratings_percentage = (len(coll_data) / (N * M) * 100) \n",
    "print(f\"Non-nan ratings percentage: {np.round(non_nan_ratings_percentage,3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "3ca5bd28-648d-4812-923c-1b97f4b711fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average number of ratings per customer : 19.89\n",
      "Average number of ratings per product: 14.63\n"
     ]
    }
   ],
   "source": [
    "avg_nratings_per_user = coll_data.groupby(user_key).size().mean()\n",
    "avg_nratings_per_movie = coll_data.groupby(item_key).size().mean()\n",
    "print(f\"Average number of ratings per customer : {avg_nratings_per_user:.2f}\")\n",
    "print(f\"Average number of ratings per product: {avg_nratings_per_movie:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "01a72bc1-78c6-4ead-b28b-abb0a17873a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Splitting\n",
    "X = coll_data.copy()\n",
    "y = coll_data['customer_id']\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b70bb14a-b22d-4283-9d34-67b59d96b3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mapper = dict(zip(np.unique(coll_data[user_key]), list(range(N))))\n",
    "item_mapper = dict(zip(np.unique(coll_data[item_key]), list(range(M))))\n",
    "user_inverse_mapper = dict(zip(list(range(N)), np.unique(coll_data[user_key])))\n",
    "item_inverse_mapper = dict(zip(list(range(M)), np.unique(coll_data[item_key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c030f351-d414-410f-a4e2-be5ae058f3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Y_from_ratings(data, N, M):\n",
    "    Y = np.zeros((N, M))\n",
    "    Y.fill(np.nan)\n",
    "    for index, val in data.iterrows():\n",
    "        n = user_mapper[val[user_key]]\n",
    "        m = item_mapper[val[item_key]]\n",
    "        Y[n, m] = val[\"star_rating\"]\n",
    "\n",
    "    return Y\n",
    "\n",
    "train_mat = create_Y_from_ratings(X_train, N, M)\n",
    "valid_mat = create_Y_from_ratings(X_valid, N, M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0446201b-ba26-4bdb-8006-f9852b0d56e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-nan elements in train_mat: 19085\n",
      "Number of non-nan elements in valid_mat: 4855\n"
     ]
    }
   ],
   "source": [
    "# What's the number of non-nan elements in train_mat (nnn_train_mat)?\n",
    "nnn_train_mat = np.sum(~np.isnan(train_mat)) \n",
    "\n",
    "# What's the number of non-nan elements in valid_mat (nnn_valid_mat)?\n",
    "nnn_valid_mat = np.sum(~np.isnan(valid_mat)) \n",
    "print(f\"Number of non-nan elements in train_mat: {nnn_train_mat}\")\n",
    "print(f\"Number of non-nan elements in valid_mat: {nnn_valid_mat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "329bf88f-8133-49e8-823a-a03c2e5022c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "def error(Y1, Y2):\n",
    "    \"\"\"\n",
    "    Given two matrices of the same shape, \n",
    "    returns the root mean squared error (RMSE).\n",
    "    \"\"\"\n",
    "    return np.sqrt(np.nanmean((Y1 - Y2) ** 2))\n",
    "\n",
    "\n",
    "def evaluate(pred_Y, train_mat, valid_mat, model_name=\"Global average\"):\n",
    "    \"\"\"\n",
    "    Given predicted utility matrix and train and validation utility matrices \n",
    "    print train and validation RMSEs.\n",
    "    \"\"\"\n",
    "    print(\"%s train RMSE: %0.2f\" % (model_name, error(pred_Y, train_mat)))\n",
    "    print(\"%s valid RMSE: %0.2f\" % (model_name, error(pred_Y, valid_mat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0a2c14fa-0053-4ff2-b3a5-6fd4aa05b08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global average train RMSE: 1.07\n",
      "Global average valid RMSE: 1.06\n"
     ]
    }
   ],
   "source": [
    "# global average rating baseline\n",
    "avg = np.nanmean(train_mat)\n",
    "pred_g = np.zeros(train_mat.shape) + avg\n",
    "evaluate(pred_g, train_mat, valid_mat, model_name=\"Global average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "bfc44586-a17a-4aef-864d-a370f729bf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-user average train RMSE: 0.95\n",
      "Per-user average valid RMSE: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j6/44dd1c8s33xg2kn35nxq3f5m0000gn/T/ipykernel_48949/2152599090.py:2: RuntimeWarning: Mean of empty slice\n",
      "  avg_n = np.nanmean(train_mat, axis=1)\n"
     ]
    }
   ],
   "source": [
    "# Per-user average baseline\n",
    "avg_n = np.nanmean(train_mat, axis=1)\n",
    "avg_n[\n",
    "    np.isnan(avg_n)\n",
    "] = avg  \n",
    "pred_n = np.tile(avg_n[:, None], (1, M))\n",
    "evaluate(pred_n, train_mat, valid_mat, model_name=\"Per-user average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "681a3704-cc72-433d-a3d1-83c1844c1563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-product average train RMSE: 0.94\n",
      "Per-product average valid RMSE: 1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j6/44dd1c8s33xg2kn35nxq3f5m0000gn/T/ipykernel_48949/1388612677.py:2: RuntimeWarning: Mean of empty slice\n",
      "  avg_m = np.nanmean(train_mat, axis=0)\n"
     ]
    }
   ],
   "source": [
    "# Per-product average baseline\n",
    "avg_m = np.nanmean(train_mat, axis=0)\n",
    "avg_m[np.isnan(avg_m)] = avg\n",
    "pred_m = np.tile(avg_m[None, :], (N, 1))\n",
    "evaluate(pred_m, train_mat, valid_mat, model_name=\"Per-product average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ff5925cb-82d4-40de-ac29-dfdc496ceafe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Per-user and product average train RMSE: 0.89\n",
      "Per-user and product average valid RMSE: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Average of per-user and per-product average baselines\n",
    "pred_n_m = (pred_n + pred_m) * 0.5\n",
    "evaluate(pred_n_m, train_mat, valid_mat, model_name=\"Per-user and product average\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "705bb771-a661-4c89-9c40-909caf601848",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of neighbours:  10\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 1.05\n",
      "\n",
      "Number of neighbours:  15\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 1.05\n",
      "\n",
      "Number of neighbours:  18\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 1.05\n",
      "\n",
      "Number of neighbours:  20\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 1.05\n",
      "\n",
      "Number of neighbours:  40\n",
      "Global average train RMSE: 0.00\n",
      "Global average valid RMSE: 1.05\n"
     ]
    }
   ],
   "source": [
    "# K-nearest neighbours imputation\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "num_neighs = [10, 15, 18, 20, 40]\n",
    "for n_neighbors in num_neighs:\n",
    "    print(\"\\nNumber of neighbours: \", n_neighbors)\n",
    "    imputer = KNNImputer(n_neighbors=n_neighbors, keep_empty_features=True)\n",
    "    pred_knn = imputer.fit_transform(train_mat)\n",
    "    evaluate(pred_knn, train_mat, valid_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3294ab37-5558-4fed-ab30-8f9d1aac7ae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TruncatedSVD (k = 10) train RMSE: 0.83\n",
      "TruncatedSVD (k = 10) valid RMSE: 0.96\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 50) train RMSE: 0.69\n",
      "TruncatedSVD (k = 50) valid RMSE: 0.95\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 100) train RMSE: 0.57\n",
      "TruncatedSVD (k = 100) valid RMSE: 0.95\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 200) train RMSE: 0.41\n",
      "TruncatedSVD (k = 200) valid RMSE: 0.95\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 500) train RMSE: 0.15\n",
      "TruncatedSVD (k = 500) valid RMSE: 0.95\n",
      "\n",
      "\n",
      "TruncatedSVD (k = 1000) train RMSE: 0.01\n",
      "TruncatedSVD (k = 1000) valid RMSE: 0.95\n"
     ]
    }
   ],
   "source": [
    "# collaborative filtering with TruncatedSVD()\n",
    "def reconstruct_svd(Z, W, avg_n, avg_m):\n",
    "    return Z @ W + 0.5 * avg_n[:, None] + 0.5 * avg_m[None]\n",
    "\n",
    "\n",
    "train_mat_svd = train_mat - 0.5 * avg_n[:, None] - 0.5 * avg_m[None]\n",
    "train_mat_svd = np.nan_to_num(train_mat_svd)\n",
    "\n",
    "k_range = [10, 50, 100, 200, 500, 1000]\n",
    "for k in k_range:\n",
    "    print(\"\\n\")\n",
    "    tsvd = TruncatedSVD(n_components=k)\n",
    "    Z = tsvd.fit_transform(train_mat_svd)\n",
    "    W = tsvd.components_\n",
    "    X_hat = reconstruct_svd(Z, W, avg_n, avg_m)\n",
    "    evaluate(X_hat, train_mat, valid_mat, model_name=\"TruncatedSVD (k = %d)\" % k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e24b2cfc-a3ce-43ea-927c-750370cab260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using surprise package\n",
    "reader = Reader()\n",
    "data = Dataset.load_from_df(coll_data, reader)  \n",
    "\n",
    "k = 10\n",
    "algo = SVD(n_factors=k, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "869fb9dd-5ae1-4a3b-b638-f34bb774cf7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE of algorithm SVD on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9232  0.9419  0.9577  0.9425  0.9740  0.9479  0.0170  \n",
      "Fit time          0.04    0.02    0.02    0.02    0.02    0.03    0.01    \n",
      "Test time         0.01    0.01    0.01    0.01    0.01    0.01    0.00    \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.923235</td>\n",
       "      <td>0.039560</td>\n",
       "      <td>0.010284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.941899</td>\n",
       "      <td>0.023084</td>\n",
       "      <td>0.008132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.957692</td>\n",
       "      <td>0.022823</td>\n",
       "      <td>0.008161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.942477</td>\n",
       "      <td>0.022872</td>\n",
       "      <td>0.008036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.974015</td>\n",
       "      <td>0.022733</td>\n",
       "      <td>0.007917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_rmse  fit_time  test_time\n",
       "0   0.923235  0.039560   0.010284\n",
       "1   0.941899  0.023084   0.008132\n",
       "2   0.957692  0.022823   0.008161\n",
       "3   0.942477  0.022872   0.008036\n",
       "4   0.974015  0.022733   0.007917"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cross_validate(algo, data, measures=[\"RMSE\"], cv=5, verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b799cd-cfa4-4744-aea8-1be3aa49174b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:563]",
   "language": "python",
   "name": "conda-env-563-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
